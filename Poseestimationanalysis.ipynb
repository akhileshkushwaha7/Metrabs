{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Processed video saved as output_video3d-36.mp4\n",
      "Pose data saved as 2dand3dposedata.xlsx\n",
      "\n",
      "Gait Metrics:\n",
      "Stride Time Left (s): 0.97\n",
      "Stride Time Right (s): 1.08\n",
      "Stride Length Left (m): 1597.56\n",
      "Stride Length Right (m): 1089.24\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (m/s): 1641.56\n",
      "Gait Speed Right (m/s): 1004.44\n",
      "Avg Left Knee Angle 2D (deg): 172.90\n",
      "Avg Right Knee Angle 2D (deg): 160.95\n",
      "Avg Left Hip Angle 2D (deg): 170.35\n",
      "Avg Right Hip Angle 2D (deg): 160.23\n",
      "Avg Left Knee Angle 3D (deg): 162.53\n",
      "Avg Right Knee Angle 3D (deg): 161.61\n",
      "Avg Left Hip Angle 3D (deg): 168.36\n",
      "Avg Right Hip Angle 3D (deg): 163.25\n",
      "Gait metrics saved to 'gait_metrics.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_io as tfio\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Your existing functions (extract_model, draw_skeleton, process_frame, process_video) remain unchanged\n",
    "def extract_model(zip_path, extract_to=\"models\"):\n",
    "    \"\"\"Extracts a zip file and returns the extracted directory path.\"\"\"\n",
    "    extract_dir = os.path.join(os.path.dirname(zip_path), extract_to)\n",
    "\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    model_dir = os.path.join(extract_dir, os.path.splitext(os.path.basename(zip_path))[0])\n",
    "    return model_dir\n",
    "\n",
    "def draw_skeleton(frame, keypoints, skeleton_edges):\n",
    "    \"\"\"Draws skeleton on the frame using detected keypoints.\"\"\"\n",
    "    for (i, j) in skeleton_edges:\n",
    "        pt1, pt2 = keypoints[i], keypoints[j]\n",
    "\n",
    "        # Check if confidence is available (shape [N, 24, 3] expected)\n",
    "        if keypoints.shape[-1] == 3:  \n",
    "            if (pt1[2] > 0.5) and (pt2[2] > 0.5):  # Confidence threshold\n",
    "                cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)  # Blue lines\n",
    "        else:  \n",
    "            # Draw without confidence check\n",
    "            cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def process_frame(frame, model, skeleton_edges):\n",
    "    \"\"\"Process a single frame using the Metrabs model and return pose visualization.\"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    original_height, original_width = frame.shape[:2]\n",
    "    frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))  # Resize as needed\n",
    "    image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "    # Run pose estimation\n",
    "    pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "    print(\"Prediction output:\", pred)  # Debugging output\n",
    "\n",
    "    if 'poses2d' in pred:\n",
    "        keypoints = pred['poses2d'].numpy()\n",
    "        print(\"Keypoints shape:\", keypoints.shape)\n",
    "\n",
    "        if keypoints.shape[0] == 0:\n",
    "            print(\"No pose detected in this frame.\")\n",
    "            return frame\n",
    "\n",
    "        # Convert normalized keypoints to pixel coordinates\n",
    "        for keypoint in keypoints:\n",
    "            keypoint[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "            keypoint[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "            frame = draw_skeleton(frame, keypoint, skeleton_edges)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def process_video(video_path, model, skeleton_edges, output_video=\"output_video3d-36.mp4\", frame_interval=10, output_excel=\"2dand3dposedata.xlsx\"):\n",
    "    \"\"\"Process video frames with pose estimation, overlay results, and save coordinates to an Excel file.\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    data_list = []  # Store pose data\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            original_height, original_width = frame.shape[:2]\n",
    "            frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "            image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "            # Run pose estimation\n",
    "            pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "\n",
    "            if 'poses2d' in pred and 'poses3d' in pred:\n",
    "                keypoints_2d = pred['poses2d'].numpy()\n",
    "                keypoints_3d = pred['poses3d'].numpy()\n",
    "\n",
    "                if keypoints_2d.shape[0] == 0:\n",
    "                    print(f\"No pose detected in frame {frame_count}\")\n",
    "                else:\n",
    "                    # Convert normalized keypoints to pixel coordinates\n",
    "                    for i in range(keypoints_2d.shape[0]):  # Iterate over detected poses\n",
    "                        if keypoints_2d[i].shape[0] > 0 and keypoints_3d[i].shape[0] > 0:  # Check for valid keypoints\n",
    "                            kpt_2d = keypoints_2d[i]  # Get keypoints for person i\n",
    "                            kpt_3d = keypoints_3d[i]\n",
    "\n",
    "                            # Scale keypoints to original frame size\n",
    "                            kpt_2d[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "                            kpt_2d[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "                            frame = draw_skeleton(frame, kpt_2d, skeleton_edges)\n",
    "\n",
    "                            # Store frame-wise keypoints\n",
    "                            for j in range(min(kpt_2d.shape[0], kpt_3d.shape[0])):  # Ensure we only access valid joints\n",
    "                            \n",
    "                                data_list.append([\n",
    "                                    frame_count, \n",
    "                                    i, \n",
    "                                    j, \n",
    "                                    kpt_2d[j][0], \n",
    "                                    kpt_2d[j][1], \n",
    "                                      # Populate confidence for 2D keypoints\n",
    "                                    kpt_3d[j][0], \n",
    "                                    kpt_3d[j][1], \n",
    "                                    kpt_3d[j][2],  # Include Z coordinate for 3D keypoints\n",
    "                                     # Populate confidence for 3D keypoints\n",
    "                                ])\n",
    "                        else:\n",
    "                            print(f\"Invalid keypoints for frame {frame_count}, person {i}\")\n",
    "\n",
    "        out.write(frame)  # Write frame to output video\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Convert collected data to a Pandas DataFrame\n",
    "    df = pd.DataFrame(data_list, columns=['Frame', 'Person', 'Joint', 'X_2D', 'Y_2D', 'X_3D', 'Y_3D', 'Z_3D'])\n",
    "\n",
    "    # Save to Excel file\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Processed video saved as {output_video}\")\n",
    "    print(f\"Pose data saved as {output_excel}\")\n",
    "\n",
    "def calculate_gait_metrics(df, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate gait metrics from 2D and 3D pose data.\"\"\"\n",
    "    # Key joint indices for SMPL_24 (adjust based on your model documentation)\n",
    "    # Example: Assuming pelvis=0, left_hip=1, left_knee=4, left_ankle=7, right_hip=2, right_knee=5, right_ankle=8\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    # Filter data for one person (assuming Person=0)\n",
    "    df_person = df[df['Person'] == 0]\n",
    "\n",
    "    # Extract key joint coordinates over time\n",
    "    left_ankle_2d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "    right_ankle_2d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "    left_ankle_3d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "    right_ankle_3d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "\n",
    "    # Detect heel strikes (simplified: lowest Y/Z position of ankle)\n",
    "    left_strikes = []\n",
    "    right_strikes = []\n",
    "    for i in range(1, len(left_ankle_3d) - 1):\n",
    "        if left_ankle_3d[i][3] < left_ankle_3d[i-1][3] and left_ankle_3d[i][3] < left_ankle_3d[i+1][3]:  # Local minima in Z\n",
    "            left_strikes.append(left_ankle_3d[i])\n",
    "        if right_ankle_3d[i][3] < right_ankle_3d[i-1][3] and right_ankle_3d[i][3] < right_ankle_3d[i+1][3]:\n",
    "            right_strikes.append(right_ankle_3d[i])\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    left_strikes = np.array(left_strikes)\n",
    "    right_strikes = np.array(right_strikes)\n",
    "\n",
    "    # 1. Stride Time (seconds between consecutive strikes of same foot)\n",
    "    if len(left_strikes) > 1:\n",
    "        stride_times_left = np.diff(left_strikes[:, 0]) / fps  # Frame difference to seconds\n",
    "        stride_time_left = np.mean(stride_times_left)\n",
    "    else:\n",
    "        stride_time_left = np.nan\n",
    "    if len(right_strikes) > 1:\n",
    "        stride_times_right = np.diff(right_strikes[:, 0]) / fps\n",
    "        stride_time_right = np.mean(stride_times_right)\n",
    "    else:\n",
    "        stride_time_right = np.nan\n",
    "\n",
    "    # 2. Stride Length (distance between consecutive strikes in 3D)\n",
    "    if len(left_strikes) > 1:\n",
    "        stride_lengths_left = [distance.euclidean(left_strikes[i][1:4], left_strikes[i+1][1:4]) for i in range(len(left_strikes)-1)]\n",
    "        stride_length_left = np.mean(stride_lengths_left)\n",
    "    else:\n",
    "        stride_length_left = np.nan\n",
    "    if len(right_strikes) > 1:\n",
    "        stride_lengths_right = [distance.euclidean(right_strikes[i][1:4], right_strikes[i+1][1:4]) for i in range(len(right_strikes)-1)]\n",
    "        stride_length_right = np.mean(stride_lengths_right)\n",
    "    else:\n",
    "        stride_length_right = np.nan\n",
    "\n",
    "    # 3. Cadence (steps per minute)\n",
    "    total_steps = len(left_strikes) + len(right_strikes)\n",
    "    total_time = (df['Frame'].max() - df['Frame'].min()) / fps / 60  # Total time in minutes\n",
    "    cadence = total_steps / total_time if total_time > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (meters per second, assuming stride length in meters)\n",
    "    gait_speed_left = stride_length_left / stride_time_left if stride_time_left > 0 else np.nan\n",
    "    gait_speed_right = stride_length_right / stride_time_right if stride_time_right > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (frame-by-frame for 2D and 3D)\n",
    "    angles_2d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    angles_3d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        # Extract coordinates for joints\n",
    "        def get_coords(joint, dim='2D'):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            if dim == '2D':\n",
    "                return row[['X_2D', 'Y_2D']].values[0] if not row.empty else np.array([np.nan, np.nan])\n",
    "            else:\n",
    "                return row[['X_3D', 'Y_3D', 'Z_3D']].values[0] if not row.empty else np.array([np.nan, np.nan, np.nan])\n",
    "\n",
    "        # 2D vectors\n",
    "        left_hip_2d = get_coords('left_hip', '2D')\n",
    "        left_knee_2d = get_coords('left_knee', '2D')\n",
    "        left_ankle_2d = get_coords('left_ankle', '2D')\n",
    "        right_hip_2d = get_coords('right_hip', '2D')\n",
    "        right_knee_2d = get_coords('right_knee', '2D')\n",
    "        right_ankle_2d = get_coords('right_ankle', '2D')\n",
    "        spine_2d = get_coords('spine1', '2D')\n",
    "\n",
    "        # 3D vectors\n",
    "        left_hip_3d = get_coords('left_hip', '3D')\n",
    "        left_knee_3d = get_coords('left_knee', '3D')\n",
    "        left_ankle_3d = get_coords('left_ankle', '3D')\n",
    "        right_hip_3d = get_coords('right_hip', '3D')\n",
    "        right_knee_3d = get_coords('right_knee', '3D')\n",
    "        right_ankle_3d = get_coords('right_ankle', '3D')\n",
    "        spine_3d = get_coords('spine1', '3D')\n",
    "\n",
    "        # Calculate angles (degrees)\n",
    "        def angle_between(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        # Knee angles\n",
    "        angles_2d['left_knee'].append(angle_between(left_hip_2d - left_knee_2d, left_ankle_2d - left_knee_2d))\n",
    "        angles_2d['right_knee'].append(angle_between(right_hip_2d - right_knee_2d, right_ankle_2d - right_knee_2d))\n",
    "        angles_3d['left_knee'].append(angle_between(left_hip_3d - left_knee_3d, left_ankle_3d - left_knee_3d))\n",
    "        angles_3d['right_knee'].append(angle_between(right_hip_3d - right_knee_3d, right_ankle_3d - right_knee_3d))\n",
    "\n",
    "        # Hip angles\n",
    "        angles_2d['left_hip'].append(angle_between(spine_2d - left_hip_2d, left_knee_2d - left_hip_2d))\n",
    "        angles_2d['right_hip'].append(angle_between(spine_2d - right_hip_2d, right_knee_2d - right_hip_2d))\n",
    "        angles_3d['left_hip'].append(angle_between(spine_3d - left_hip_3d, left_knee_3d - left_hip_3d))\n",
    "        angles_3d['right_hip'].append(angle_between(spine_3d - right_hip_3d, right_knee_3d - right_hip_3d))\n",
    "\n",
    "    # Average angles\n",
    "    avg_angles_2d = {k: np.nanmean(v) for k, v in angles_2d.items()}\n",
    "    avg_angles_3d = {k: np.nanmean(v) for k, v in angles_3d.items()}\n",
    "\n",
    "    # Compile results\n",
    "    metrics = {\n",
    "        'Stride Time Left (s)': stride_time_left,\n",
    "        'Stride Time Right (s)': stride_time_right,\n",
    "        'Stride Length Left (m)': stride_length_left,\n",
    "        'Stride Length Right (m)': stride_length_right,\n",
    "        'Cadence (steps/min)': cadence,\n",
    "        'Gait Speed Left (m/s)': gait_speed_left,\n",
    "        'Gait Speed Right (m/s)': gait_speed_right,\n",
    "        'Avg Left Knee Angle 2D (deg)': avg_angles_2d['left_knee'],\n",
    "        'Avg Right Knee Angle 2D (deg)': avg_angles_2d['right_knee'],\n",
    "        'Avg Left Hip Angle 2D (deg)': avg_angles_2d['left_hip'],\n",
    "        'Avg Right Hip Angle 2D (deg)': avg_angles_2d['right_hip'],\n",
    "        'Avg Left Knee Angle 3D (deg)': avg_angles_3d['left_knee'],\n",
    "        'Avg Right Knee Angle 3D (deg)': avg_angles_3d['right_knee'],\n",
    "        'Avg Left Hip Angle 3D (deg)': avg_angles_3d['left_hip'],\n",
    "        'Avg Right Hip Angle 3D (deg)': avg_angles_3d['right_hip']\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    zip_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\metrabs_mob3l_y4t.zip\"\n",
    "    video_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\video.mp4\"\n",
    "    output_excel = \"2dand3dposedata.xlsx\"\n",
    "\n",
    "    # Extract and load the model\n",
    "    model_path = extract_model(zip_path)\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Load skeleton information\n",
    "    skeleton = 'smpl_24'\n",
    "    joint_names = model.per_skeleton_joint_names[skeleton].numpy().astype(str)\n",
    "    joint_edges = model.per_skeleton_joint_edges[skeleton].numpy()\n",
    "\n",
    "    # Process video\n",
    "    process_video(video_path, model, joint_edges, output_excel=output_excel)\n",
    "\n",
    "    # Load the generated Excel file\n",
    "    df = pd.read_excel(output_excel)\n",
    "    fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Calculate gait metrics\n",
    "    metrics = calculate_gait_metrics(df, fps, joint_edges, joint_names)\n",
    "\n",
    "    # Print and save results\n",
    "    print(\"\\nGait Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_df.to_excel(\"gait_metrics.xlsx\", index=False)\n",
    "    print(\"Gait metrics saved to 'gait_metrics.xlsx'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\akhileshsing2024\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Processed video saved as output_video3d-36.mp4\n",
      "Pose data saved as 2dand3dposedata.xlsx\n",
      "\n",
      "2D Gait Metrics:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (pixels): 479.35\n",
      "Stride Length Right (pixels): 351.42\n",
      "Cadence (steps/min): 95.90\n",
      "Gait Speed Left (pixels/s): 383.10\n",
      "Gait Speed Right (pixels/s): 280.85\n",
      "Avg Left Knee Angle (deg): 172.90\n",
      "Avg Right Knee Angle (deg): 160.95\n",
      "Avg Left Hip Angle (deg): 170.35\n",
      "Avg Right Hip Angle (deg): 160.23\n",
      "\n",
      "3D Gait Metrics:\n",
      "Stride Time Left (s): 0.97\n",
      "Stride Time Right (s): 1.08\n",
      "Stride Length Left (m): 1597.56\n",
      "Stride Length Right (m): 1089.24\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (m/s): 1641.56\n",
      "Gait Speed Right (m/s): 1004.44\n",
      "Avg Left Knee Angle (deg): 162.53\n",
      "Avg Right Knee Angle (deg): 161.61\n",
      "Avg Left Hip Angle (deg): 168.36\n",
      "Avg Right Hip Angle (deg): 163.25\n",
      "Gait metrics saved to 'gait_metrics_separate.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_io as tfio\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def extract_model(zip_path, extract_to=\"models\"):\n",
    "    \"\"\"Extracts a zip file and returns the extracted directory path.\"\"\"\n",
    "    extract_dir = os.path.join(os.path.dirname(zip_path), extract_to)\n",
    "\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    model_dir = os.path.join(extract_dir, os.path.splitext(os.path.basename(zip_path))[0])\n",
    "    return model_dir\n",
    "\n",
    "def draw_skeleton(frame, keypoints, skeleton_edges):\n",
    "    \"\"\"Draws skeleton on the frame using detected keypoints.\"\"\"\n",
    "    for (i, j) in skeleton_edges:\n",
    "        pt1, pt2 = keypoints[i], keypoints[j]\n",
    "\n",
    "        # Check if confidence is available (shape [N, 24, 3] expected)\n",
    "        if keypoints.shape[-1] == 3:  \n",
    "            if (pt1[2] > 0.5) and (pt2[2] > 0.5):  # Confidence threshold\n",
    "                cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)  # Blue lines\n",
    "        else:  \n",
    "            # Draw without confidence check\n",
    "            cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "# def process_frame(frame, model, skeleton_edges):\n",
    "#     \"\"\"Process a single frame using the Metrabs model and return pose visualization.\"\"\"\n",
    "#     frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     original_height, original_width = frame.shape[:2]\n",
    "#     frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))  # Resize as needed\n",
    "#     image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "#     # Run pose estimation\n",
    "#     pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "#     print(\"Prediction output:\", pred)  # Debugging output\n",
    "\n",
    "#     if 'poses2d' in pred:\n",
    "#         keypoints = pred['poses2d'].numpy()\n",
    "#         print(\"Keypoints shape:\", keypoints.shape)\n",
    "\n",
    "#         if keypoints.shape[0] == 0:\n",
    "#             print(\"No pose detected in this frame.\")\n",
    "#             return frame\n",
    "\n",
    "#         # Convert normalized keypoints to pixel coordinates\n",
    "#         for keypoint in keypoints:\n",
    "#             keypoint[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "#             keypoint[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "#             frame = draw_skeleton(frame, keypoint, skeleton_edges)\n",
    "\n",
    "#     return frame\n",
    "\n",
    "\n",
    "def process_video(video_path, model, skeleton_edges, output_video=\"output_video3d-36.mp4\", frame_interval=10, output_excel=\"2dand3dposedata.xlsx\"):\n",
    "    \"\"\"Process video frames with pose estimation, overlay results, and save coordinates to an Excel file.\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    data_list = []  # Store pose data\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            original_height, original_width = frame.shape[:2]\n",
    "            frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "            image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "            # Run pose estimation\n",
    "            pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "\n",
    "            if 'poses2d' in pred and 'poses3d' in pred:\n",
    "                keypoints_2d = pred['poses2d'].numpy()\n",
    "                keypoints_3d = pred['poses3d'].numpy()\n",
    "\n",
    "                if keypoints_2d.shape[0] == 0:\n",
    "                    print(f\"No pose detected in frame {frame_count}\")\n",
    "                else:\n",
    "                    # Convert normalized keypoints to pixel coordinates\n",
    "                    for i in range(keypoints_2d.shape[0]):  # Iterate over detected poses\n",
    "                        if keypoints_2d[i].shape[0] > 0 and keypoints_3d[i].shape[0] > 0:  # Check for valid keypoints\n",
    "                            kpt_2d = keypoints_2d[i]  # Get keypoints for person i\n",
    "                            kpt_3d = keypoints_3d[i]\n",
    "\n",
    "                            # Scale keypoints to original frame size\n",
    "                            kpt_2d[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "                            kpt_2d[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "                            frame = draw_skeleton(frame, kpt_2d, skeleton_edges)\n",
    "\n",
    "                            # Store frame-wise keypoints\n",
    "                            for j in range(min(kpt_2d.shape[0], kpt_3d.shape[0])):  # Ensure we only access valid joints\n",
    "                            \n",
    "                                data_list.append([\n",
    "                                    frame_count, \n",
    "                                    i, \n",
    "                                    j, \n",
    "                                    kpt_2d[j][0], \n",
    "                                    kpt_2d[j][1], \n",
    "                                      # Populate confidence for 2D keypoints\n",
    "                                    kpt_3d[j][0], \n",
    "                                    kpt_3d[j][1], \n",
    "                                    kpt_3d[j][2],  # Include Z coordinate for 3D keypoints\n",
    "                                     # Populate confidence for 3D keypoints\n",
    "                                ])\n",
    "                                \n",
    "                        else:\n",
    "                            print(f\"Invalid keypoints for frame {frame_count}, person {i}\")\n",
    "\n",
    "        out.write(frame)  # Write frame to output video\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Convert collected data to a Pandas DataFrame\n",
    "    df = pd.DataFrame(data_list, columns=['Frame', 'Person', 'Joint', 'X_2D', 'Y_2D', 'X_3D', 'Y_3D', 'Z_3D'])\n",
    "\n",
    "    # Save to Excel file\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Processed video saved as {output_video}\")\n",
    "    print(f\"Pose data saved as {output_excel}\")\n",
    "\n",
    "\n",
    "def calculate_gait_metrics_2d(df, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate gait metrics using only 2D coordinates.\"\"\"\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    df_person = df[df['Person'] == 0]\n",
    "    left_ankle_2d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "    right_ankle_2d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "\n",
    "    # Detect heel strikes in 2D (lowest Y_2D position)\n",
    "    left_strikes_2d = []\n",
    "    right_strikes_2d = []\n",
    "    for i in range(1, len(left_ankle_2d) - 1):\n",
    "        if left_ankle_2d[i][2] < left_ankle_2d[i-1][2] and left_ankle_2d[i][2] < left_ankle_2d[i+1][2]:  # Local minima in Y_2D\n",
    "            left_strikes_2d.append(left_ankle_2d[i])\n",
    "        if right_ankle_2d[i][2] < right_ankle_2d[i-1][2] and right_ankle_2d[i][2] < right_ankle_2d[i+1][2]:\n",
    "            right_strikes_2d.append(right_ankle_2d[i])\n",
    "\n",
    "    left_strikes_2d = np.array(left_strikes_2d)\n",
    "    right_strikes_2d = np.array(right_strikes_2d)\n",
    "\n",
    "    # 1. Stride Time (2D)\n",
    "    stride_time_left_2d = np.mean(np.diff(left_strikes_2d[:, 0]) / fps) if len(left_strikes_2d) > 1 else np.nan\n",
    "    stride_time_right_2d = np.mean(np.diff(right_strikes_2d[:, 0]) / fps) if len(right_strikes_2d) > 1 else np.nan\n",
    "\n",
    "    # 2. Stride Length (2D, in pixels)\n",
    "    stride_length_left_2d = np.mean([distance.euclidean(left_strikes_2d[i][1:3], left_strikes_2d[i+1][1:3]) \n",
    "                                    for i in range(len(left_strikes_2d)-1)]) if len(left_strikes_2d) > 1 else np.nan\n",
    "    stride_length_right_2d = np.mean([distance.euclidean(right_strikes_2d[i][1:3], right_strikes_2d[i+1][1:3]) \n",
    "                                     for i in range(len(right_strikes_2d)-1)]) if len(right_strikes_2d) > 1 else np.nan\n",
    "\n",
    "    # 3. Cadence (2D)\n",
    "    total_steps_2d = len(left_strikes_2d) + len(right_strikes_2d)\n",
    "    total_time_2d = (df['Frame'].max() - df['Frame'].min()) / fps / 60\n",
    "    cadence_2d = total_steps_2d / total_time_2d if total_time_2d > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (2D, pixels per second)\n",
    "    gait_speed_left_2d = stride_length_left_2d / stride_time_left_2d if stride_time_left_2d > 0 else np.nan\n",
    "    gait_speed_right_2d = stride_length_right_2d / stride_time_right_2d if stride_time_right_2d > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (2D)\n",
    "    angles_2d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        def get_coords_2d(joint):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            return row[['X_2D', 'Y_2D']].values[0] if not row.empty else np.array([np.nan, np.nan])\n",
    "\n",
    "        left_hip_2d = get_coords_2d('left_hip')\n",
    "        left_knee_2d = get_coords_2d('left_knee')\n",
    "        left_ankle_2d = get_coords_2d('left_ankle')\n",
    "        right_hip_2d = get_coords_2d('right_hip')\n",
    "        right_knee_2d = get_coords_2d('right_knee')\n",
    "        right_ankle_2d = get_coords_2d('right_ankle')\n",
    "        spine_2d = get_coords_2d('spine1')\n",
    "\n",
    "        def angle_between_2d(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        angles_2d['left_knee'].append(angle_between_2d(left_hip_2d - left_knee_2d, left_ankle_2d - left_knee_2d))\n",
    "        angles_2d['right_knee'].append(angle_between_2d(right_hip_2d - right_knee_2d, right_ankle_2d - right_knee_2d))\n",
    "        angles_2d['left_hip'].append(angle_between_2d(spine_2d - left_hip_2d, left_knee_2d - left_hip_2d))\n",
    "        angles_2d['right_hip'].append(angle_between_2d(spine_2d - right_hip_2d, right_knee_2d - right_hip_2d))\n",
    "\n",
    "    avg_angles_2d = {k: np.nanmean(v) for k, v in angles_2d.items()}\n",
    "\n",
    "    return {\n",
    "        'Stride Time Left (s)': stride_time_left_2d,\n",
    "        'Stride Time Right (s)': stride_time_right_2d,\n",
    "        'Stride Length Left (pixels)': stride_length_left_2d,\n",
    "        'Stride Length Right (pixels)': stride_length_right_2d,\n",
    "        'Cadence (steps/min)': cadence_2d,\n",
    "        'Gait Speed Left (pixels/s)': gait_speed_left_2d,\n",
    "        'Gait Speed Right (pixels/s)': gait_speed_right_2d,\n",
    "        'Avg Left Knee Angle (deg)': avg_angles_2d['left_knee'],\n",
    "        'Avg Right Knee Angle (deg)': avg_angles_2d['right_knee'],\n",
    "        'Avg Left Hip Angle (deg)': avg_angles_2d['left_hip'],\n",
    "        'Avg Right Hip Angle (deg)': avg_angles_2d['right_hip']\n",
    "    }\n",
    "\n",
    "def calculate_gait_metrics_3d(df, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate gait metrics using only 3D coordinates.\"\"\"\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    df_person = df[df['Person'] == 0]\n",
    "    left_ankle_3d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "    right_ankle_3d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "\n",
    "    # Detect heel strikes in 3D (lowest Z_3D position)\n",
    "    left_strikes_3d = []\n",
    "    right_strikes_3d = []\n",
    "    for i in range(1, len(left_ankle_3d) - 1):\n",
    "        if left_ankle_3d[i][3] < left_ankle_3d[i-1][3] and left_ankle_3d[i][3] < left_ankle_3d[i+1][3]:  # Local minima in Z_3D\n",
    "            left_strikes_3d.append(left_ankle_3d[i])\n",
    "        if right_ankle_3d[i][3] < right_ankle_3d[i-1][3] and right_ankle_3d[i][3] < right_ankle_3d[i+1][3]:\n",
    "            right_strikes_3d.append(right_ankle_3d[i])\n",
    "\n",
    "    left_strikes_3d = np.array(left_strikes_3d)\n",
    "    right_strikes_3d = np.array(right_strikes_3d)\n",
    "\n",
    "    # 1. Stride Time (3D)\n",
    "    stride_time_left_3d = np.mean(np.diff(left_strikes_3d[:, 0]) / fps) if len(left_strikes_3d) > 1 else np.nan\n",
    "    stride_time_right_3d = np.mean(np.diff(right_strikes_3d[:, 0]) / fps) if len(right_strikes_3d) > 1 else np.nan\n",
    "\n",
    "    # 2. Stride Length (3D, in model units, assumed meters)\n",
    "    stride_length_left_3d = np.mean([distance.euclidean(left_strikes_3d[i][1:4], left_strikes_3d[i+1][1:4]) \n",
    "                                    for i in range(len(left_strikes_3d)-1)]) if len(left_strikes_3d) > 1 else np.nan\n",
    "    stride_length_right_3d = np.mean([distance.euclidean(right_strikes_3d[i][1:4], right_strikes_3d[i+1][1:4]) \n",
    "                                     for i in range(len(right_strikes_3d)-1)]) if len(right_strikes_3d) > 1 else np.nan\n",
    "\n",
    "    # 3. Cadence (3D)\n",
    "    total_steps_3d = len(left_strikes_3d) + len(right_strikes_3d)\n",
    "    total_time_3d = (df['Frame'].max() - df['Frame'].min()) / fps / 60\n",
    "    cadence_3d = total_steps_3d / total_time_3d if total_time_3d > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (3D, assumed meters per second)\n",
    "    gait_speed_left_3d = stride_length_left_3d / stride_time_left_3d if stride_time_left_3d > 0 else np.nan\n",
    "    gait_speed_right_3d = stride_length_right_3d / stride_time_right_3d if stride_time_right_3d > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (3D)\n",
    "    angles_3d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        def get_coords_3d(joint):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            return row[['X_3D', 'Y_3D', 'Z_3D']].values[0] if not row.empty else np.array([np.nan, np.nan, np.nan])\n",
    "\n",
    "        left_hip_3d = get_coords_3d('left_hip')\n",
    "        left_knee_3d = get_coords_3d('left_knee')\n",
    "        left_ankle_3d = get_coords_3d('left_ankle')\n",
    "        right_hip_3d = get_coords_3d('right_hip')\n",
    "        right_knee_3d = get_coords_3d('right_knee')\n",
    "        right_ankle_3d = get_coords_3d('right_ankle')\n",
    "        spine_3d = get_coords_3d('spine1')\n",
    "\n",
    "        def angle_between_3d(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        angles_3d['left_knee'].append(angle_between_3d(left_hip_3d - left_knee_3d, left_ankle_3d - left_knee_3d))\n",
    "        angles_3d['right_knee'].append(angle_between_3d(right_hip_3d - right_knee_3d, right_ankle_3d - right_knee_3d))\n",
    "        angles_3d['left_hip'].append(angle_between_3d(spine_3d - left_hip_3d, left_knee_3d - left_hip_3d))\n",
    "        angles_3d['right_hip'].append(angle_between_3d(spine_3d - right_hip_3d, right_knee_3d - right_hip_3d))\n",
    "\n",
    "    avg_angles_3d = {k: np.nanmean(v) for k, v in angles_3d.items()}\n",
    "\n",
    "    return {\n",
    "        'Stride Time Left (s)': stride_time_left_3d,\n",
    "        'Stride Time Right (s)': stride_time_right_3d,\n",
    "        'Stride Length Left (m)': stride_length_left_3d,\n",
    "        'Stride Length Right (m)': stride_length_right_3d,\n",
    "        'Cadence (steps/min)': cadence_3d,\n",
    "        'Gait Speed Left (m/s)': gait_speed_left_3d,\n",
    "        'Gait Speed Right (m/s)': gait_speed_right_3d,\n",
    "        'Avg Left Knee Angle (deg)': avg_angles_3d['left_knee'],\n",
    "        'Avg Right Knee Angle (deg)': avg_angles_3d['right_knee'],\n",
    "        'Avg Left Hip Angle (deg)': avg_angles_3d['left_hip'],\n",
    "        'Avg Right Hip Angle (deg)': avg_angles_3d['right_hip']\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    zip_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\metrabs_mob3l_y4t.zip\"\n",
    "    video_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\video.mp4\"\n",
    "    output_excel = \"2dand3dposedata.xlsx\"\n",
    "\n",
    "    # Extract and load the model\n",
    "    model_path = extract_model(zip_path)\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Load skeleton information\n",
    "    skeleton = 'smpl_24'\n",
    "    joint_names = model.per_skeleton_joint_names[skeleton].numpy().astype(str)\n",
    "    joint_edges = model.per_skeleton_joint_edges[skeleton].numpy()\n",
    "\n",
    "    # Process video\n",
    "    process_video(video_path, model, joint_edges, output_excel=output_excel)\n",
    "\n",
    "    # Load the generated Excel file\n",
    "    df = pd.read_excel(output_excel)\n",
    "    fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Calculate gait metrics separately\n",
    "    metrics_2d = calculate_gait_metrics_2d(df, fps, joint_edges, joint_names)\n",
    "    metrics_3d = calculate_gait_metrics_3d(df, fps, joint_edges, joint_names)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n2D Gait Metrics:\")\n",
    "    for key, value in metrics_2d.items():\n",
    "        print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "    print(\"\\n3D Gait Metrics:\")\n",
    "    for key, value in metrics_3d.items():\n",
    "        print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "    # Save to Excel\n",
    "    metrics_df_2d = pd.DataFrame([metrics_2d])\n",
    "    metrics_df_3d = pd.DataFrame([metrics_3d])\n",
    "    with pd.ExcelWriter(\"gait_metrics_separate.xlsx\") as writer:\n",
    "        metrics_df_2d.to_excel(writer, sheet_name='2D Metrics', index=False)\n",
    "        metrics_df_3d.to_excel(writer, sheet_name='3D Metrics', index=False)\n",
    "    print(\"Gait metrics saved to 'gait_metrics_separate.xlsx'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\akhileshsing2024\\\\Downloads'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working code to calculate the 2d and 3d pose estimation and gait analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Processed video saved as output_video3d-36.mp4\n",
      "Pose data saved as 2dand3dposedata.xlsx\n",
      "\n",
      "Processing Person 0...\n",
      "2D Metrics for Person 0:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (pixels): 479.35\n",
      "Stride Length Right (pixels): 351.42\n",
      "Cadence (steps/min): 95.90\n",
      "Gait Speed Left (pixels/s): 383.10\n",
      "Gait Speed Right (pixels/s): 280.85\n",
      "Avg Left Knee Angle (deg): 172.90\n",
      "Avg Right Knee Angle (deg): 160.95\n",
      "Avg Left Hip Angle (deg): 170.35\n",
      "Avg Right Hip Angle (deg): 160.23\n",
      "3D Metrics for Person 0:\n",
      "Stride Time Left (s): 0.97\n",
      "Stride Time Right (s): 1.08\n",
      "Stride Length Left (m): 1597.56\n",
      "Stride Length Right (m): 1089.24\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (m/s): 1641.56\n",
      "Gait Speed Right (m/s): 1004.44\n",
      "Avg Left Knee Angle (deg): 162.53\n",
      "Avg Right Knee Angle (deg): 161.61\n",
      "Avg Left Hip Angle (deg): 168.36\n",
      "Avg Right Hip Angle (deg): 163.25\n",
      "\n",
      "Processing Person 1...\n",
      "2D Metrics for Person 1:\n",
      "Stride Time Left (s): 1.36\n",
      "Stride Time Right (s): 1.56\n",
      "Stride Length Left (pixels): 551.84\n",
      "Stride Length Right (pixels): 677.06\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (pixels/s): 407.11\n",
      "Gait Speed Right (pixels/s): 432.89\n",
      "Avg Left Knee Angle (deg): 170.97\n",
      "Avg Right Knee Angle (deg): 164.42\n",
      "Avg Left Hip Angle (deg): 172.95\n",
      "Avg Right Hip Angle (deg): 161.18\n",
      "3D Metrics for Person 1:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.67\n",
      "Stride Length Left (m): 814.72\n",
      "Stride Length Right (m): 1193.24\n",
      "Cadence (steps/min): 71.93\n",
      "Gait Speed Left (m/s): 651.12\n",
      "Gait Speed Right (m/s): 715.23\n",
      "Avg Left Knee Angle (deg): 161.81\n",
      "Avg Right Knee Angle (deg): 166.18\n",
      "Avg Left Hip Angle (deg): 169.23\n",
      "Avg Right Hip Angle (deg): 164.69\n",
      "\n",
      "Processing Person 2...\n",
      "2D Metrics for Person 2:\n",
      "Stride Time Left (s): 1.33\n",
      "Stride Time Right (s): 1.67\n",
      "Stride Length Left (pixels): 474.06\n",
      "Stride Length Right (pixels): 200.95\n",
      "Cadence (steps/min): 87.91\n",
      "Gait Speed Left (pixels/s): 355.19\n",
      "Gait Speed Right (pixels/s): 120.45\n",
      "Avg Left Knee Angle (deg): 169.66\n",
      "Avg Right Knee Angle (deg): 157.98\n",
      "Avg Left Hip Angle (deg): 171.89\n",
      "Avg Right Hip Angle (deg): 161.66\n",
      "3D Metrics for Person 2:\n",
      "Stride Time Left (s): 1.39\n",
      "Stride Time Right (s): 1.39\n",
      "Stride Length Left (m): 820.20\n",
      "Stride Length Right (m): 851.42\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (m/s): 589.95\n",
      "Gait Speed Right (m/s): 612.41\n",
      "Avg Left Knee Angle (deg): 158.88\n",
      "Avg Right Knee Angle (deg): 160.15\n",
      "Avg Left Hip Angle (deg): 166.65\n",
      "Avg Right Hip Angle (deg): 163.72\n",
      "\n",
      "Processing Person 3...\n",
      "2D Metrics for Person 3:\n",
      "Stride Time Left (s): 0.97\n",
      "Stride Time Right (s): 0.97\n",
      "Stride Length Left (pixels): 300.84\n",
      "Stride Length Right (pixels): 306.03\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (pixels/s): 309.13\n",
      "Gait Speed Right (pixels/s): 314.46\n",
      "Avg Left Knee Angle (deg): 170.59\n",
      "Avg Right Knee Angle (deg): 163.82\n",
      "Avg Left Hip Angle (deg): 170.15\n",
      "Avg Right Hip Angle (deg): 162.17\n",
      "3D Metrics for Person 3:\n",
      "Stride Time Left (s): 1.56\n",
      "Stride Time Right (s): 1.56\n",
      "Stride Length Left (m): 1762.73\n",
      "Stride Length Right (m): 1839.48\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (m/s): 1127.02\n",
      "Gait Speed Right (m/s): 1176.09\n",
      "Avg Left Knee Angle (deg): 158.63\n",
      "Avg Right Knee Angle (deg): 161.61\n",
      "Avg Left Hip Angle (deg): 167.01\n",
      "Avg Right Hip Angle (deg): 163.86\n",
      "\n",
      "Processing Person 4...\n",
      "2D Metrics for Person 4:\n",
      "Stride Time Left (s): 2.22\n",
      "Stride Time Right (s): 2.22\n",
      "Stride Length Left (pixels): 753.74\n",
      "Stride Length Right (pixels): 752.30\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (pixels/s): 338.85\n",
      "Gait Speed Right (pixels/s): 338.20\n",
      "Avg Left Knee Angle (deg): 174.34\n",
      "Avg Right Knee Angle (deg): 163.91\n",
      "Avg Left Hip Angle (deg): 172.17\n",
      "Avg Right Hip Angle (deg): 162.19\n",
      "3D Metrics for Person 4:\n",
      "Stride Time Left (s): 1.46\n",
      "Stride Time Right (s): 1.46\n",
      "Stride Length Left (m): 1378.12\n",
      "Stride Length Right (m): 1504.38\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (m/s): 944.05\n",
      "Gait Speed Right (m/s): 1030.55\n",
      "Avg Left Knee Angle (deg): 163.74\n",
      "Avg Right Knee Angle (deg): 166.65\n",
      "Avg Left Hip Angle (deg): 169.17\n",
      "Avg Right Hip Angle (deg): 164.87\n",
      "\n",
      "Processing Person 5...\n",
      "2D Metrics for Person 5:\n",
      "Stride Time Left (s): 2.71\n",
      "Stride Time Right (s): 2.71\n",
      "Stride Length Left (pixels): 200.76\n",
      "Stride Length Right (pixels): 210.75\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (pixels/s): 74.05\n",
      "Gait Speed Right (pixels/s): 77.74\n",
      "Avg Left Knee Angle (deg): 153.69\n",
      "Avg Right Knee Angle (deg): 143.12\n",
      "Avg Left Hip Angle (deg): 153.64\n",
      "Avg Right Hip Angle (deg): 158.97\n",
      "3D Metrics for Person 5:\n",
      "Stride Time Left (s): 2.50\n",
      "Stride Time Right (s): 2.50\n",
      "Stride Length Left (m): 1366.24\n",
      "Stride Length Right (m): 1457.62\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (m/s): 545.95\n",
      "Gait Speed Right (m/s): 582.47\n",
      "Avg Left Knee Angle (deg): 136.69\n",
      "Avg Right Knee Angle (deg): 139.95\n",
      "Avg Left Hip Angle (deg): 154.97\n",
      "Avg Right Hip Angle (deg): 153.48\n",
      "\n",
      "Processing Person 6...\n",
      "2D Metrics for Person 6:\n",
      "Stride Time Left (s): N/A\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (pixels): N/A\n",
      "Stride Length Right (pixels): 22.76\n",
      "Cadence (steps/min): 26.97\n",
      "Gait Speed Left (pixels/s): N/A\n",
      "Gait Speed Right (pixels/s): 18.19\n",
      "Avg Left Knee Angle (deg): 149.71\n",
      "Avg Right Knee Angle (deg): 143.45\n",
      "Avg Left Hip Angle (deg): 146.64\n",
      "Avg Right Hip Angle (deg): 157.85\n",
      "3D Metrics for Person 6:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (m): 1148.30\n",
      "Stride Length Right (m): 1144.91\n",
      "Cadence (steps/min): 35.96\n",
      "Gait Speed Left (m/s): 917.72\n",
      "Gait Speed Right (m/s): 915.01\n",
      "Avg Left Knee Angle (deg): 132.05\n",
      "Avg Right Knee Angle (deg): 137.76\n",
      "Avg Left Hip Angle (deg): 150.92\n",
      "Avg Right Hip Angle (deg): 151.50\n",
      "\n",
      "Gait metrics for all persons saved to 'gait_metrics_per_person.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_io as tfio\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def extract_model(zip_path, extract_to=\"models\"):\n",
    "    \"\"\"Extracts a zip file and returns the extracted directory path.\"\"\"\n",
    "    extract_dir = os.path.join(os.path.dirname(zip_path), extract_to)\n",
    "\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    model_dir = os.path.join(extract_dir, os.path.splitext(os.path.basename(zip_path))[0])\n",
    "    return model_dir\n",
    "\n",
    "def draw_skeleton(frame, keypoints, skeleton_edges):\n",
    "    \"\"\"Draws skeleton on the frame using detected keypoints.\"\"\"\n",
    "    for (i, j) in skeleton_edges:\n",
    "        pt1, pt2 = keypoints[i], keypoints[j]\n",
    "\n",
    "        # Check if confidence is available (shape [N, 24, 3] expected)\n",
    "        if keypoints.shape[-1] == 3:  \n",
    "            if (pt1[2] > 0.5) and (pt2[2] > 0.5):  # Confidence threshold\n",
    "                cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)  # Blue lines\n",
    "        else:  \n",
    "            # Draw without confidence check\n",
    "            cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def process_video(video_path, model, skeleton_edges, output_video=\"output_video3d-36.mp4\", frame_interval=10, output_excel=\"2dand3dposedata.xlsx\"):\n",
    "    \"\"\"Process video frames with pose estimation, overlay results, and save coordinates to an Excel file.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    data_list = []  # Store pose data\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            original_height, original_width = frame.shape[:2]\n",
    "            frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "            image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "            # Run pose estimation\n",
    "            pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "\n",
    "            if 'poses2d' in pred and 'poses3d' in pred:\n",
    "                keypoints_2d = pred['poses2d'].numpy()\n",
    "                keypoints_3d = pred['poses3d'].numpy()\n",
    "\n",
    "                if keypoints_2d.shape[0] == 0:\n",
    "                    print(f\"No pose detected in frame {frame_count}\")\n",
    "                else:\n",
    "                    # Convert normalized keypoints to pixel coordinates\n",
    "                    for i in range(keypoints_2d.shape[0]):  # Iterate over detected poses\n",
    "                        if keypoints_2d[i].shape[0] > 0 and keypoints_3d[i].shape[0] > 0:  # Check for valid keypoints\n",
    "                            kpt_2d = keypoints_2d[i]  # Get keypoints for person i\n",
    "                            kpt_3d = keypoints_3d[i]\n",
    "\n",
    "                            # Scale keypoints to original frame size\n",
    "                            kpt_2d[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "                            kpt_2d[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "                            frame = draw_skeleton(frame, kpt_2d, skeleton_edges)\n",
    "\n",
    "                            # Store frame-wise keypoints\n",
    "                            for j in range(min(kpt_2d.shape[0], kpt_3d.shape[0])):  # Ensure we only access valid joints\n",
    "                            \n",
    "                                data_list.append([\n",
    "                                    frame_count, \n",
    "                                    i, \n",
    "                                    j, \n",
    "                                    kpt_2d[j][0], \n",
    "                                    kpt_2d[j][1], \n",
    "                                      # Populate confidence for 2D keypoints\n",
    "                                    kpt_3d[j][0], \n",
    "                                    kpt_3d[j][1], \n",
    "                                    kpt_3d[j][2],  # Include Z coordinate for 3D keypoints\n",
    "                                     # Populate confidence for 3D keypoints\n",
    "                                ])\n",
    "                                \n",
    "                        else:\n",
    "                            print(f\"Invalid keypoints for frame {frame_count}, person {i}\")\n",
    "\n",
    "        out.write(frame)  # Write frame to output video\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Convert collected data to a Pandas DataFrame\n",
    "    df = pd.DataFrame(data_list, columns=['Frame', 'Person', 'Joint', 'X_2D', 'Y_2D', 'X_3D', 'Y_3D', 'Z_3D'])\n",
    "\n",
    "    # Save to Excel file\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Processed video saved as {output_video}\")\n",
    "    print(f\"Pose data saved as {output_excel}\")\n",
    "def calculate_gait_metrics_2d(df, person_id, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate 2D gait metrics for a specific person.\"\"\"\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    df_person = df[df['Person'] == person_id]\n",
    "    if df_person.empty:\n",
    "        return None  # No data for this person\n",
    "\n",
    "    left_ankle_2d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "    right_ankle_2d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "\n",
    "    # Detect heel strikes in 2D (lowest Y_2D position)\n",
    "    left_strikes_2d = []\n",
    "    right_strikes_2d = []\n",
    "    for i in range(1, len(left_ankle_2d) - 1):\n",
    "        if left_ankle_2d[i][2] < left_ankle_2d[i-1][2] and left_ankle_2d[i][2] < left_ankle_2d[i+1][2]:\n",
    "            left_strikes_2d.append(left_ankle_2d[i])\n",
    "        if right_ankle_2d[i][2] < right_ankle_2d[i-1][2] and right_ankle_2d[i][2] < right_ankle_2d[i+1][2]:\n",
    "            right_strikes_2d.append(right_ankle_2d[i])\n",
    "\n",
    "    left_strikes_2d = np.array(left_strikes_2d)\n",
    "    right_strikes_2d = np.array(right_strikes_2d)\n",
    "\n",
    "    # 1. Stride Time (2D)\n",
    "    stride_time_left_2d = np.mean(np.diff(left_strikes_2d[:, 0]) / fps) if len(left_strikes_2d) > 1 else np.nan\n",
    "    stride_time_right_2d = np.mean(np.diff(right_strikes_2d[:, 0]) / fps) if len(right_strikes_2d) > 1 else np.nan\n",
    "\n",
    "    # 2. Stride Length (2D, in pixels)\n",
    "    stride_length_left_2d = np.mean([distance.euclidean(left_strikes_2d[i][1:3], left_strikes_2d[i+1][1:3]) \n",
    "                                    for i in range(len(left_strikes_2d)-1)]) if len(left_strikes_2d) > 1 else np.nan\n",
    "    stride_length_right_2d = np.mean([distance.euclidean(right_strikes_2d[i][1:3], right_strikes_2d[i+1][1:3]) \n",
    "                                     for i in range(len(right_strikes_2d)-1)]) if len(right_strikes_2d) > 1 else np.nan\n",
    "\n",
    "    # 3. Cadence (2D)\n",
    "    total_steps_2d = len(left_strikes_2d) + len(right_strikes_2d)\n",
    "    total_time_2d = (df_person['Frame'].max() - df_person['Frame'].min()) / fps / 60 if not df_person['Frame'].empty else 0\n",
    "    cadence_2d = total_steps_2d / total_time_2d if total_time_2d > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (2D, pixels per second)\n",
    "    gait_speed_left_2d = stride_length_left_2d / stride_time_left_2d if stride_time_left_2d > 0 else np.nan\n",
    "    gait_speed_right_2d = stride_length_right_2d / stride_time_right_2d if stride_time_right_2d > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (2D)\n",
    "    angles_2d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        def get_coords_2d(joint):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            return row[['X_2D', 'Y_2D']].values[0] if not row.empty else np.array([np.nan, np.nan])\n",
    "\n",
    "        left_hip_2d = get_coords_2d('left_hip')\n",
    "        left_knee_2d = get_coords_2d('left_knee')\n",
    "        left_ankle_2d = get_coords_2d('left_ankle')\n",
    "        right_hip_2d = get_coords_2d('right_hip')\n",
    "        right_knee_2d = get_coords_2d('right_knee')\n",
    "        right_ankle_2d = get_coords_2d('right_ankle')\n",
    "        spine_2d = get_coords_2d('spine1')\n",
    "\n",
    "        def angle_between_2d(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        angles_2d['left_knee'].append(angle_between_2d(left_hip_2d - left_knee_2d, left_ankle_2d - left_knee_2d))\n",
    "        angles_2d['right_knee'].append(angle_between_2d(right_hip_2d - right_knee_2d, right_ankle_2d - right_knee_2d))\n",
    "        angles_2d['left_hip'].append(angle_between_2d(spine_2d - left_hip_2d, left_knee_2d - left_hip_2d))\n",
    "        angles_2d['right_hip'].append(angle_between_2d(spine_2d - right_hip_2d, right_knee_2d - right_hip_2d))\n",
    "\n",
    "    avg_angles_2d = {k: np.nanmean(v) for k, v in angles_2d.items()}\n",
    "\n",
    "    return {\n",
    "        'Person': person_id,\n",
    "        'Stride Time Left (s)': stride_time_left_2d,\n",
    "        'Stride Time Right (s)': stride_time_right_2d,\n",
    "        'Stride Length Left (pixels)': stride_length_left_2d,\n",
    "        'Stride Length Right (pixels)': stride_length_right_2d,\n",
    "        'Cadence (steps/min)': cadence_2d,\n",
    "        'Gait Speed Left (pixels/s)': gait_speed_left_2d,\n",
    "        'Gait Speed Right (pixels/s)': gait_speed_right_2d,\n",
    "        'Avg Left Knee Angle (deg)': avg_angles_2d['left_knee'],\n",
    "        'Avg Right Knee Angle (deg)': avg_angles_2d['right_knee'],\n",
    "        'Avg Left Hip Angle (deg)': avg_angles_2d['left_hip'],\n",
    "        'Avg Right Hip Angle (deg)': avg_angles_2d['right_hip']\n",
    "    }\n",
    "\n",
    "def calculate_gait_metrics_3d(df, person_id, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate 3D gait metrics for a specific person.\"\"\"\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    df_person = df[df['Person'] == person_id]\n",
    "    if df_person.empty:\n",
    "        return None  # No data for this person\n",
    "\n",
    "    left_ankle_3d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "    right_ankle_3d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "\n",
    "    # Detect heel strikes in 3D (lowest Z_3D position)\n",
    "    left_strikes_3d = []\n",
    "    right_strikes_3d = []\n",
    "    for i in range(1, len(left_ankle_3d) - 1):\n",
    "        if left_ankle_3d[i][3] < left_ankle_3d[i-1][3] and left_ankle_3d[i][3] < left_ankle_3d[i+1][3]:\n",
    "            left_strikes_3d.append(left_ankle_3d[i])\n",
    "        if right_ankle_3d[i][3] < right_ankle_3d[i-1][3] and right_ankle_3d[i][3] < right_ankle_3d[i+1][3]:\n",
    "            right_strikes_3d.append(right_ankle_3d[i])\n",
    "\n",
    "    left_strikes_3d = np.array(left_strikes_3d)\n",
    "    right_strikes_3d = np.array(right_strikes_3d)\n",
    "\n",
    "    # 1. Stride Time (3D)\n",
    "    stride_time_left_3d = np.mean(np.diff(left_strikes_3d[:, 0]) / fps) if len(left_strikes_3d) > 1 else np.nan\n",
    "    stride_time_right_3d = np.mean(np.diff(right_strikes_3d[:, 0]) / fps) if len(right_strikes_3d) > 1 else np.nan\n",
    "\n",
    "    # 2. Stride Length (3D, assumed meters)\n",
    "    stride_length_left_3d = np.mean([distance.euclidean(left_strikes_3d[i][1:4], left_strikes_3d[i+1][1:4]) \n",
    "                                    for i in range(len(left_strikes_3d)-1)]) if len(left_strikes_3d) > 1 else np.nan\n",
    "    stride_length_right_3d = np.mean([distance.euclidean(right_strikes_3d[i][1:4], right_strikes_3d[i+1][1:4]) \n",
    "                                     for i in range(len(right_strikes_3d)-1)]) if len(right_strikes_3d) > 1 else np.nan\n",
    "\n",
    "    # 3. Cadence (3D)\n",
    "    total_steps_3d = len(left_strikes_3d) + len(right_strikes_3d)\n",
    "    total_time_3d = (df_person['Frame'].max() - df_person['Frame'].min()) / fps / 60 if not df_person['Frame'].empty else 0\n",
    "    cadence_3d = total_steps_3d / total_time_3d if total_time_3d > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (3D, assumed meters per second)\n",
    "    gait_speed_left_3d = stride_length_left_3d / stride_time_left_3d if stride_time_left_3d > 0 else np.nan\n",
    "    gait_speed_right_3d = stride_length_right_3d / stride_time_right_3d if stride_time_right_3d > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (3D)\n",
    "    angles_3d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        def get_coords_3d(joint):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            return row[['X_3D', 'Y_3D', 'Z_3D']].values[0] if not row.empty else np.array([np.nan, np.nan, np.nan])\n",
    "\n",
    "        left_hip_3d = get_coords_3d('left_hip')\n",
    "        left_knee_3d = get_coords_3d('left_knee')\n",
    "        left_ankle_3d = get_coords_3d('left_ankle')\n",
    "        right_hip_3d = get_coords_3d('right_hip')\n",
    "        right_knee_3d = get_coords_3d('right_knee')\n",
    "        right_ankle_3d = get_coords_3d('right_ankle')\n",
    "        spine_3d = get_coords_3d('spine1')\n",
    "\n",
    "        def angle_between_3d(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        angles_3d['left_knee'].append(angle_between_3d(left_hip_3d - left_knee_3d, left_ankle_3d - left_knee_3d))\n",
    "        angles_3d['right_knee'].append(angle_between_3d(right_hip_3d - right_knee_3d, right_ankle_3d - right_knee_3d))\n",
    "        angles_3d['left_hip'].append(angle_between_3d(spine_3d - left_hip_3d, left_knee_3d - left_hip_3d))\n",
    "        angles_3d['right_hip'].append(angle_between_3d(spine_3d - right_hip_3d, right_knee_3d - right_hip_3d))\n",
    "\n",
    "    avg_angles_3d = {k: np.nanmean(v) for k, v in angles_3d.items()}\n",
    "\n",
    "    return {\n",
    "        'Person': person_id,\n",
    "        'Stride Time Left (s)': stride_time_left_3d,\n",
    "        'Stride Time Right (s)': stride_time_right_3d,\n",
    "        'Stride Length Left (m)': stride_length_left_3d,\n",
    "        'Stride Length Right (m)': stride_length_right_3d,\n",
    "        'Cadence (steps/min)': cadence_3d,\n",
    "        'Gait Speed Left (m/s)': gait_speed_left_3d,\n",
    "        'Gait Speed Right (m/s)': gait_speed_right_3d,\n",
    "        'Avg Left Knee Angle (deg)': avg_angles_3d['left_knee'],\n",
    "        'Avg Right Knee Angle (deg)': avg_angles_3d['right_knee'],\n",
    "        'Avg Left Hip Angle (deg)': avg_angles_3d['left_hip'],\n",
    "        'Avg Right Hip Angle (deg)': avg_angles_3d['right_hip']\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    zip_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\metrabs_mob3l_y4t.zip\"\n",
    "    video_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\video.mp4\"\n",
    "    output_excel = \"2dand3dposedata.xlsx\"\n",
    "\n",
    "    # Extract and load the model\n",
    "    model_path = extract_model(zip_path)\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Load skeleton information\n",
    "    skeleton = 'smpl_24'\n",
    "    joint_names = model.per_skeleton_joint_names[skeleton].numpy().astype(str)\n",
    "    joint_edges = model.per_skeleton_joint_edges[skeleton].numpy()\n",
    "\n",
    "    # Process video\n",
    "    process_video(video_path, model, joint_edges, output_excel=output_excel)\n",
    "\n",
    "    # Load the generated Excel file\n",
    "    df = pd.read_excel(output_excel)\n",
    "    fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Calculate gait metrics for each person (0 to 6)\n",
    "    metrics_2d_all = []\n",
    "    metrics_3d_all = []\n",
    "    for person_id in range(7):  # Assuming 7 persons (0 to 6)\n",
    "        print(f\"\\nProcessing Person {person_id}...\")\n",
    "        \n",
    "        # 2D Metrics\n",
    "        metrics_2d = calculate_gait_metrics_2d(df, person_id, fps, joint_edges, joint_names)\n",
    "        if metrics_2d:\n",
    "            metrics_2d_all.append(metrics_2d)\n",
    "            print(f\"2D Metrics for Person {person_id}:\")\n",
    "            for key, value in metrics_2d.items():\n",
    "                if key != 'Person':\n",
    "                    print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "        # 3D Metrics\n",
    "        metrics_3d = calculate_gait_metrics_3d(df, person_id, fps, joint_edges, joint_names)\n",
    "        if metrics_3d:\n",
    "            metrics_3d_all.append(metrics_3d)\n",
    "            print(f\"3D Metrics for Person {person_id}:\")\n",
    "            for key, value in metrics_3d.items():\n",
    "                if key != 'Person':\n",
    "                    print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "    # Save to Excel with separate sheets for 2D and 3D\n",
    "    metrics_df_2d = pd.DataFrame(metrics_2d_all)\n",
    "    metrics_df_3d = pd.DataFrame(metrics_3d_all)\n",
    "    with pd.ExcelWriter(\"gait_metrics_per_person.xlsx\") as writer:\n",
    "        metrics_df_2d.to_excel(writer, sheet_name='2D Metrics', index=False)\n",
    "        metrics_df_3d.to_excel(writer, sheet_name='3D Metrics', index=False)\n",
    "    print(\"\\nGait metrics for all persons saved to 'gait_metrics_per_person.xlsx'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_add_trackable_child', '_add_variable_with_custom_getter', '_checkpoint_dependencies', '_deferred_dependencies', '_delete_tracking', '_deserialization_dependencies', '_deserialize_from_proto', '_export_to_saved_model_graph', '_gather_saveables_for_checkpoint', '_handle_deferred_dependencies', '_lookup_dependency', '_maybe_initialize_trackable', '_name_based_attribute_restore', '_name_based_restores', '_no_dependency', '_object_identifier', '_preload_simple_restoration', '_restore_from_tensors', '_self_name_based_restores', '_self_saveable_object_factories', '_self_setattr_tracking', '_self_unconditional_checkpoint_dependencies', '_self_unconditional_deferred_dependencies', '_self_unconditional_dependency_names', '_self_update_uid', '_serialize_to_proto', '_serialize_to_tensors', '_setattr_tracking', '_tf_api_names', '_tf_api_names_v1', '_track_trackable', '_trackable_children', '_unconditional_checkpoint_dependencies', '_unconditional_dependency_names', '_update_uid', 'crop_model', 'detect_poses', 'detect_poses_batched', 'detector', 'estimate_poses', 'estimate_poses_batched', 'graph_debug_info', 'joint_edges', 'joint_names', 'per_skeleton_indices', 'per_skeleton_joint_edges', 'per_skeleton_joint_names', 'signatures', 'tensorflow_git_version', 'tensorflow_version']\n",
      "Model loaded successfully!\n",
      "Processed video saved as output_video3d_withlabelschanged.mp4\n",
      "Pose data saved as 2dand3dposedatawithlabelschanged.xlsx\n",
      "Detected 8 persons in the video.\n",
      "\n",
      "Processing Person 0...\n",
      "2D Metrics for Person 0:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (pixels): 479.35\n",
      "Stride Length Right (pixels): 351.42\n",
      "Cadence (steps/min): 95.90\n",
      "Gait Speed Left (pixels/s): 383.10\n",
      "Gait Speed Right (pixels/s): 280.85\n",
      "Avg Left Knee Angle (deg): 172.90\n",
      "Avg Right Knee Angle (deg): 160.95\n",
      "Avg Left Hip Angle (deg): 170.35\n",
      "Avg Right Hip Angle (deg): 160.23\n",
      "3D Metrics for Person 0:\n",
      "Stride Time Left (s): 0.97\n",
      "Stride Time Right (s): 1.08\n",
      "Stride Length Left (m): 1597.56\n",
      "Stride Length Right (m): 1089.24\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (m/s): 1641.56\n",
      "Gait Speed Right (m/s): 1004.44\n",
      "Avg Left Knee Angle (deg): 162.53\n",
      "Avg Right Knee Angle (deg): 161.61\n",
      "Avg Left Hip Angle (deg): 168.36\n",
      "Avg Right Hip Angle (deg): 163.25\n",
      "\n",
      "Processing Person 1...\n",
      "2D Metrics for Person 1:\n",
      "Stride Time Left (s): 1.36\n",
      "Stride Time Right (s): 1.56\n",
      "Stride Length Left (pixels): 551.84\n",
      "Stride Length Right (pixels): 677.06\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (pixels/s): 407.11\n",
      "Gait Speed Right (pixels/s): 432.89\n",
      "Avg Left Knee Angle (deg): 170.97\n",
      "Avg Right Knee Angle (deg): 164.42\n",
      "Avg Left Hip Angle (deg): 172.95\n",
      "Avg Right Hip Angle (deg): 161.18\n",
      "3D Metrics for Person 1:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.67\n",
      "Stride Length Left (m): 814.72\n",
      "Stride Length Right (m): 1193.24\n",
      "Cadence (steps/min): 71.93\n",
      "Gait Speed Left (m/s): 651.12\n",
      "Gait Speed Right (m/s): 715.23\n",
      "Avg Left Knee Angle (deg): 161.81\n",
      "Avg Right Knee Angle (deg): 166.18\n",
      "Avg Left Hip Angle (deg): 169.23\n",
      "Avg Right Hip Angle (deg): 164.69\n",
      "\n",
      "Processing Person 2...\n",
      "2D Metrics for Person 2:\n",
      "Stride Time Left (s): 1.33\n",
      "Stride Time Right (s): 1.67\n",
      "Stride Length Left (pixels): 474.06\n",
      "Stride Length Right (pixels): 200.95\n",
      "Cadence (steps/min): 87.91\n",
      "Gait Speed Left (pixels/s): 355.19\n",
      "Gait Speed Right (pixels/s): 120.45\n",
      "Avg Left Knee Angle (deg): 169.66\n",
      "Avg Right Knee Angle (deg): 157.98\n",
      "Avg Left Hip Angle (deg): 171.89\n",
      "Avg Right Hip Angle (deg): 161.66\n",
      "3D Metrics for Person 2:\n",
      "Stride Time Left (s): 1.39\n",
      "Stride Time Right (s): 1.39\n",
      "Stride Length Left (m): 820.20\n",
      "Stride Length Right (m): 851.42\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (m/s): 589.95\n",
      "Gait Speed Right (m/s): 612.41\n",
      "Avg Left Knee Angle (deg): 158.88\n",
      "Avg Right Knee Angle (deg): 160.15\n",
      "Avg Left Hip Angle (deg): 166.65\n",
      "Avg Right Hip Angle (deg): 163.72\n",
      "\n",
      "Processing Person 3...\n",
      "2D Metrics for Person 3:\n",
      "Stride Time Left (s): 0.97\n",
      "Stride Time Right (s): 0.97\n",
      "Stride Length Left (pixels): 300.84\n",
      "Stride Length Right (pixels): 306.03\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (pixels/s): 309.13\n",
      "Gait Speed Right (pixels/s): 314.46\n",
      "Avg Left Knee Angle (deg): 170.59\n",
      "Avg Right Knee Angle (deg): 163.82\n",
      "Avg Left Hip Angle (deg): 170.15\n",
      "Avg Right Hip Angle (deg): 162.17\n",
      "3D Metrics for Person 3:\n",
      "Stride Time Left (s): 1.56\n",
      "Stride Time Right (s): 1.56\n",
      "Stride Length Left (m): 1762.73\n",
      "Stride Length Right (m): 1839.48\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (m/s): 1127.02\n",
      "Gait Speed Right (m/s): 1176.09\n",
      "Avg Left Knee Angle (deg): 158.63\n",
      "Avg Right Knee Angle (deg): 161.61\n",
      "Avg Left Hip Angle (deg): 167.01\n",
      "Avg Right Hip Angle (deg): 163.86\n",
      "\n",
      "Processing Person 4...\n",
      "2D Metrics for Person 4:\n",
      "Stride Time Left (s): 2.22\n",
      "Stride Time Right (s): 2.22\n",
      "Stride Length Left (pixels): 753.74\n",
      "Stride Length Right (pixels): 752.30\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (pixels/s): 338.85\n",
      "Gait Speed Right (pixels/s): 338.20\n",
      "Avg Left Knee Angle (deg): 174.34\n",
      "Avg Right Knee Angle (deg): 163.91\n",
      "Avg Left Hip Angle (deg): 172.17\n",
      "Avg Right Hip Angle (deg): 162.19\n",
      "3D Metrics for Person 4:\n",
      "Stride Time Left (s): 1.46\n",
      "Stride Time Right (s): 1.46\n",
      "Stride Length Left (m): 1378.12\n",
      "Stride Length Right (m): 1504.38\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (m/s): 944.05\n",
      "Gait Speed Right (m/s): 1030.55\n",
      "Avg Left Knee Angle (deg): 163.74\n",
      "Avg Right Knee Angle (deg): 166.65\n",
      "Avg Left Hip Angle (deg): 169.17\n",
      "Avg Right Hip Angle (deg): 164.87\n",
      "\n",
      "Processing Person 5...\n",
      "2D Metrics for Person 5:\n",
      "Stride Time Left (s): 2.71\n",
      "Stride Time Right (s): 2.71\n",
      "Stride Length Left (pixels): 200.76\n",
      "Stride Length Right (pixels): 210.75\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (pixels/s): 74.05\n",
      "Gait Speed Right (pixels/s): 77.74\n",
      "Avg Left Knee Angle (deg): 153.69\n",
      "Avg Right Knee Angle (deg): 143.12\n",
      "Avg Left Hip Angle (deg): 153.64\n",
      "Avg Right Hip Angle (deg): 158.97\n",
      "3D Metrics for Person 5:\n",
      "Stride Time Left (s): 2.50\n",
      "Stride Time Right (s): 2.50\n",
      "Stride Length Left (m): 1366.24\n",
      "Stride Length Right (m): 1457.62\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (m/s): 545.95\n",
      "Gait Speed Right (m/s): 582.47\n",
      "Avg Left Knee Angle (deg): 136.69\n",
      "Avg Right Knee Angle (deg): 139.95\n",
      "Avg Left Hip Angle (deg): 154.97\n",
      "Avg Right Hip Angle (deg): 153.48\n",
      "\n",
      "Processing Person 6...\n",
      "2D Metrics for Person 6:\n",
      "Stride Time Left (s): N/A\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (pixels): N/A\n",
      "Stride Length Right (pixels): 22.76\n",
      "Cadence (steps/min): 26.97\n",
      "Gait Speed Left (pixels/s): N/A\n",
      "Gait Speed Right (pixels/s): 18.19\n",
      "Avg Left Knee Angle (deg): 149.71\n",
      "Avg Right Knee Angle (deg): 143.45\n",
      "Avg Left Hip Angle (deg): 146.64\n",
      "Avg Right Hip Angle (deg): 157.85\n",
      "3D Metrics for Person 6:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (m): 1148.30\n",
      "Stride Length Right (m): 1144.91\n",
      "Cadence (steps/min): 35.96\n",
      "Gait Speed Left (m/s): 917.72\n",
      "Gait Speed Right (m/s): 915.01\n",
      "Avg Left Knee Angle (deg): 132.05\n",
      "Avg Right Knee Angle (deg): 137.76\n",
      "Avg Left Hip Angle (deg): 150.92\n",
      "Avg Right Hip Angle (deg): 151.50\n",
      "\n",
      "Processing Person 7...\n",
      "2D Metrics for Person 7:\n",
      "Stride Time Left (s): N/A\n",
      "Stride Time Right (s): N/A\n",
      "Stride Length Left (pixels): N/A\n",
      "Stride Length Right (pixels): N/A\n",
      "Cadence (steps/min): N/A\n",
      "Gait Speed Left (pixels/s): N/A\n",
      "Gait Speed Right (pixels/s): N/A\n",
      "Avg Left Knee Angle (deg): 113.46\n",
      "Avg Right Knee Angle (deg): 113.22\n",
      "Avg Left Hip Angle (deg): 111.21\n",
      "Avg Right Hip Angle (deg): 154.55\n",
      "3D Metrics for Person 7:\n",
      "Stride Time Left (s): N/A\n",
      "Stride Time Right (s): N/A\n",
      "Stride Length Left (m): N/A\n",
      "Stride Length Right (m): N/A\n",
      "Cadence (steps/min): N/A\n",
      "Gait Speed Left (m/s): N/A\n",
      "Gait Speed Right (m/s): N/A\n",
      "Avg Left Knee Angle (deg): 85.26\n",
      "Avg Right Knee Angle (deg): 95.45\n",
      "Avg Left Hip Angle (deg): 122.27\n",
      "Avg Right Hip Angle (deg): 130.27\n",
      "\n",
      "Gait metrics for all detected persons saved to 'gait_metrics_per_person.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_io as tfio\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def extract_model(zip_path, extract_to=\"models\"):\n",
    "    \"\"\"Extracts a zip file and returns the extracted directory path.\"\"\"\n",
    "    extract_dir = os.path.join(os.path.dirname(zip_path), extract_to)\n",
    "\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    model_dir = os.path.join(extract_dir, os.path.splitext(os.path.basename(zip_path))[0])\n",
    "    return model_dir\n",
    "\n",
    "def draw_skeleton(frame, keypoints, skeleton_edges):\n",
    "    \"\"\"Draws skeleton on the frame using detected keypoints.\"\"\"\n",
    "    for (i, j) in skeleton_edges:\n",
    "        pt1, pt2 = keypoints[i], keypoints[j]\n",
    "\n",
    "        # Check if confidence is available (shape [N, 24, 3] expected)\n",
    "        if keypoints.shape[-1] == 3:  \n",
    "            if (pt1[2] > 0.5) and (pt2[2] > 0.5):  # Confidence threshold\n",
    "                cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)  # Blue lines\n",
    "        else:  \n",
    "            # Draw without confidence check\n",
    "            cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# def process_video(video_path, model, skeleton_edges, output_video=\"output_video3d-36.mp4\", frame_interval=10, output_excel=\"2dand3dposedata.xlsx\"):\n",
    "#     \"\"\"Process video frames with pose estimation, overlay results, and save coordinates to an Excel file.\"\"\"\n",
    "    \n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     frame_width = int(cap.get(3))\n",
    "#     frame_height = int(cap.get(4))\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "#     frame_count = 0\n",
    "#     data_list = []  # Store pose data\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         if frame_count % frame_interval == 0:\n",
    "#             frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             original_height, original_width = frame.shape[:2]\n",
    "#             frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "#             image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "#             # Run pose estimation\n",
    "#             pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "\n",
    "#             if 'poses2d' in pred and 'poses3d' in pred:\n",
    "#                 keypoints_2d = pred['poses2d'].numpy()\n",
    "#                 keypoints_3d = pred['poses3d'].numpy()\n",
    "\n",
    "#                 if keypoints_2d.shape[0] == 0:\n",
    "#                     print(f\"No pose detected in frame {frame_count}\")\n",
    "#                 else:\n",
    "#                     # Convert normalized keypoints to pixel coordinates\n",
    "#                     for i in range(keypoints_2d.shape[0]):  # Iterate over detected poses\n",
    "#                         if keypoints_2d[i].shape[0] > 0 and keypoints_3d[i].shape[0] > 0:  # Check for valid keypoints\n",
    "#                             kpt_2d = keypoints_2d[i]  # Get keypoints for person i\n",
    "#                             kpt_3d = keypoints_3d[i]\n",
    "\n",
    "#                             # Scale keypoints to original frame size\n",
    "#                             kpt_2d[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "#                             kpt_2d[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "#                             frame = draw_skeleton(frame, kpt_2d, skeleton_edges)\n",
    "\n",
    "#                             # Store frame-wise keypoints\n",
    "#                             for j in range(min(kpt_2d.shape[0], kpt_3d.shape[0])):  # Ensure we only access valid joints\n",
    "#                                 data_list.append([\n",
    "#                                     frame_count, \n",
    "#                                     i, \n",
    "#                                     j, \n",
    "#                                     kpt_2d[j][0], \n",
    "#                                     kpt_2d[j][1], \n",
    "#                                     kpt_3d[j][0], \n",
    "#                                     kpt_3d[j][1], \n",
    "#                                     kpt_3d[j][2],  # Include Z coordinate for 3D keypoints\n",
    "#                                 ])\n",
    "#                         else:\n",
    "#                             print(f\"Invalid keypoints for frame {frame_count}, person {i}\")\n",
    "\n",
    "#         out.write(frame)  # Write frame to output video\n",
    "#         frame_count += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "\n",
    "#     # Convert collected data to a Pandas DataFrame\n",
    "#     df = pd.DataFrame(data_list, columns=['Frame', 'Person', 'Joint', 'X_2D', 'Y_2D', 'X_3D', 'Y_3D', 'Z_3D'])\n",
    "\n",
    "#     # Save to Excel file\n",
    "#     df.to_excel(output_excel, index=False)\n",
    "#     print(f\"Processed video saved as {output_video}\")\n",
    "#     print(f\"Pose data saved as {output_excel}\")\n",
    "def process_video(video_path, model, skeleton_edges, output_video=\"output_video3d_withlabelschanged.mp4\", frame_interval=10, output_excel=\"2dand3dposedatawithlabelschanged.xlsx\"):\n",
    "    \"\"\"Process video frames with pose estimation, overlay skeletons and person labels, and save coordinates to an Excel file.\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    data_list = []  # Store pose data\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            original_height, original_width = frame.shape[:2]\n",
    "            frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "            image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "            # Run pose estimation\n",
    "            pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "\n",
    "            if 'poses2d' in pred and 'poses3d' in pred:\n",
    "                keypoints_2d = pred['poses2d'].numpy()\n",
    "                keypoints_3d = pred['poses3d'].numpy()\n",
    "\n",
    "                if keypoints_2d.shape[0] == 0:\n",
    "                    print(f\"No pose detected in frame {frame_count}\")\n",
    "                else:\n",
    "                    # Iterate over detected poses (persons)\n",
    "                    for i in range(keypoints_2d.shape[0]):\n",
    "                        if keypoints_2d[i].shape[0] > 0 and keypoints_3d[i].shape[0] > 0:  # Check for valid keypoints\n",
    "                            kpt_2d = keypoints_2d[i]  # Get keypoints for person i\n",
    "                            kpt_3d = keypoints_3d[i]\n",
    "\n",
    "                            # Scale keypoints to original frame size\n",
    "                            kpt_2d[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "                            kpt_2d[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "                            # Draw skeleton\n",
    "                            frame = draw_skeleton(frame, kpt_2d, skeleton_edges)\n",
    "\n",
    "                            # Add person label (e.g., \"Person 1\", \"Person 2\", etc.)\n",
    "                            person_label = f\"Person {i + 1}\"  # Person ID starts from 1\n",
    "                            label_position = (int(kpt_2d[0][0]), int(kpt_2d[0][1] - 20))  # Position above the head (e.g., pelvis or first keypoint)\n",
    "                            cv2.putText(frame, person_label, label_position, \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                            # Store frame-wise keypoints\n",
    "                            for j in range(min(kpt_2d.shape[0], kpt_3d.shape[0])):  # Ensure we only access valid joints\n",
    "                                data_list.append([\n",
    "                                    frame_count, \n",
    "                                    i, \n",
    "                                    j, \n",
    "                                    kpt_2d[j][0], \n",
    "                                    kpt_2d[j][1], \n",
    "                                    kpt_3d[j][0], \n",
    "                                    kpt_3d[j][1], \n",
    "                                    kpt_3d[j][2],  # Include Z coordinate for 3D keypoints\n",
    "                                ])\n",
    "                        else:\n",
    "                            print(f\"Invalid keypoints for frame {frame_count}, person {i}\")\n",
    "\n",
    "        out.write(frame)  # Write frame to output video\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Convert collected data to a Pandas DataFrame\n",
    "    df = pd.DataFrame(data_list, columns=['Frame', 'Person', 'Joint', 'X_2D', 'Y_2D', 'X_3D', 'Y_3D', 'Z_3D'])\n",
    "\n",
    "    # Save to Excel file\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Processed video saved as {output_video}\")\n",
    "    print(f\"Pose data saved as {output_excel}\")\n",
    "\n",
    "def calculate_gait_metrics_2d(df, person_id, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate 2D gait metrics for a specific person.\"\"\"\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    df_person = df[df['Person'] == person_id]\n",
    "    if df_person.empty:\n",
    "        return None  # No data for this person\n",
    "\n",
    "    left_ankle_2d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "    right_ankle_2d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "\n",
    "    # Detect heel strikes in 2D (lowest Y_2D position)\n",
    "    left_strikes_2d = []\n",
    "    right_strikes_2d = []\n",
    "    for i in range(1, len(left_ankle_2d) - 1):\n",
    "        if left_ankle_2d[i][2] < left_ankle_2d[i-1][2] and left_ankle_2d[i][2] < left_ankle_2d[i+1][2]:\n",
    "            left_strikes_2d.append(left_ankle_2d[i])\n",
    "        if right_ankle_2d[i][2] < right_ankle_2d[i-1][2] and right_ankle_2d[i][2] < right_ankle_2d[i+1][2]:\n",
    "            right_strikes_2d.append(right_ankle_2d[i])\n",
    "\n",
    "    left_strikes_2d = np.array(left_strikes_2d)\n",
    "    right_strikes_2d = np.array(right_strikes_2d)\n",
    "\n",
    "    # 1. Stride Time (2D)\n",
    "    stride_time_left_2d = np.mean(np.diff(left_strikes_2d[:, 0]) / fps) if len(left_strikes_2d) > 1 else np.nan\n",
    "    stride_time_right_2d = np.mean(np.diff(right_strikes_2d[:, 0]) / fps) if len(right_strikes_2d) > 1 else np.nan\n",
    "\n",
    "    # 2. Stride Length (2D, in pixels)\n",
    "    stride_length_left_2d = np.mean([distance.euclidean(left_strikes_2d[i][1:3], left_strikes_2d[i+1][1:3]) \n",
    "                                    for i in range(len(left_strikes_2d)-1)]) if len(left_strikes_2d) > 1 else np.nan\n",
    "    stride_length_right_2d = np.mean([distance.euclidean(right_strikes_2d[i][1:3], right_strikes_2d[i+1][1:3]) \n",
    "                                     for i in range(len(right_strikes_2d)-1)]) if len(right_strikes_2d) > 1 else np.nan\n",
    "\n",
    "    # 3. Cadence (2D)\n",
    "    total_steps_2d = len(left_strikes_2d) + len(right_strikes_2d)\n",
    "    total_time_2d = (df_person['Frame'].max() - df_person['Frame'].min()) / fps / 60 if not df_person['Frame'].empty else 0\n",
    "    cadence_2d = total_steps_2d / total_time_2d if total_time_2d > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (2D, pixels per second)\n",
    "    gait_speed_left_2d = stride_length_left_2d / stride_time_left_2d if stride_time_left_2d > 0 else np.nan\n",
    "    gait_speed_right_2d = stride_length_right_2d / stride_time_right_2d if stride_time_right_2d > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (2D)\n",
    "    angles_2d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        def get_coords_2d(joint):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            return row[['X_2D', 'Y_2D']].values[0] if not row.empty else np.array([np.nan, np.nan])\n",
    "\n",
    "        left_hip_2d = get_coords_2d('left_hip')\n",
    "        left_knee_2d = get_coords_2d('left_knee')\n",
    "        left_ankle_2d = get_coords_2d('left_ankle')\n",
    "        right_hip_2d = get_coords_2d('right_hip')\n",
    "        right_knee_2d = get_coords_2d('right_knee')\n",
    "        right_ankle_2d = get_coords_2d('right_ankle')\n",
    "        spine_2d = get_coords_2d('spine1')\n",
    "\n",
    "        def angle_between_2d(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        angles_2d['left_knee'].append(angle_between_2d(left_hip_2d - left_knee_2d, left_ankle_2d - left_knee_2d))\n",
    "        angles_2d['right_knee'].append(angle_between_2d(right_hip_2d - right_knee_2d, right_ankle_2d - right_knee_2d))\n",
    "        angles_2d['left_hip'].append(angle_between_2d(spine_2d - left_hip_2d, left_knee_2d - left_hip_2d))\n",
    "        angles_2d['right_hip'].append(angle_between_2d(spine_2d - right_hip_2d, right_knee_2d - right_hip_2d))\n",
    "\n",
    "    avg_angles_2d = {k: np.nanmean(v) for k, v in angles_2d.items()}\n",
    "\n",
    "    return {\n",
    "        'Person': person_id,\n",
    "        'Stride Time Left (s)': stride_time_left_2d,\n",
    "        'Stride Time Right (s)': stride_time_right_2d,\n",
    "        'Stride Length Left (pixels)': stride_length_left_2d,\n",
    "        'Stride Length Right (pixels)': stride_length_right_2d,\n",
    "        'Cadence (steps/min)': cadence_2d,\n",
    "        'Gait Speed Left (pixels/s)': gait_speed_left_2d,\n",
    "        'Gait Speed Right (pixels/s)': gait_speed_right_2d,\n",
    "        'Avg Left Knee Angle (deg)': avg_angles_2d['left_knee'],\n",
    "        'Avg Right Knee Angle (deg)': avg_angles_2d['right_knee'],\n",
    "        'Avg Left Hip Angle (deg)': avg_angles_2d['left_hip'],\n",
    "        'Avg Right Hip Angle (deg)': avg_angles_2d['right_hip']\n",
    "    }\n",
    "def calculate_gait_metrics_3d(df, person_id, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate 3D gait metrics for a specific person.\"\"\"\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    df_person = df[df['Person'] == person_id]\n",
    "    if df_person.empty:\n",
    "        return None  # No data for this person\n",
    "\n",
    "    left_ankle_3d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "    right_ankle_3d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "\n",
    "    # Detect heel strikes in 3D (lowest Z_3D position)\n",
    "    left_strikes_3d = []\n",
    "    right_strikes_3d = []\n",
    "    for i in range(1, len(left_ankle_3d) - 1):\n",
    "        if left_ankle_3d[i][3] < left_ankle_3d[i-1][3] and left_ankle_3d[i][3] < left_ankle_3d[i+1][3]:\n",
    "            left_strikes_3d.append(left_ankle_3d[i])\n",
    "        if right_ankle_3d[i][3] < right_ankle_3d[i-1][3] and right_ankle_3d[i][3] < right_ankle_3d[i+1][3]:\n",
    "            right_strikes_3d.append(right_ankle_3d[i])\n",
    "\n",
    "    left_strikes_3d = np.array(left_strikes_3d)\n",
    "    right_strikes_3d = np.array(right_strikes_3d)\n",
    "\n",
    "    # 1. Stride Time (3D)\n",
    "    stride_time_left_3d = np.mean(np.diff(left_strikes_3d[:, 0]) / fps) if len(left_strikes_3d) > 1 else np.nan\n",
    "    stride_time_right_3d = np.mean(np.diff(right_strikes_3d[:, 0]) / fps) if len(right_strikes_3d) > 1 else np.nan\n",
    "\n",
    "    # 2. Stride Length (3D, assumed meters)\n",
    "    stride_length_left_3d = np.mean([distance.euclidean(left_strikes_3d[i][1:4], left_strikes_3d[i+1][1:4]) \n",
    "                                    for i in range(len(left_strikes_3d)-1)]) if len(left_strikes_3d) > 1 else np.nan\n",
    "    stride_length_right_3d = np.mean([distance.euclidean(right_strikes_3d[i][1:4], right_strikes_3d[i+1][1:4]) \n",
    "                                     for i in range(len(right_strikes_3d)-1)]) if len(right_strikes_3d) > 1 else np.nan\n",
    "\n",
    "    # 3. Cadence (3D)\n",
    "    total_steps_3d = len(left_strikes_3d) + len(right_strikes_3d)\n",
    "    total_time_3d = (df_person['Frame'].max() - df_person['Frame'].min()) / fps / 60 if not df_person['Frame'].empty else 0\n",
    "    cadence_3d = total_steps_3d / total_time_3d if total_time_3d > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (3D, assumed meters per second)\n",
    "    gait_speed_left_3d = stride_length_left_3d / stride_time_left_3d if stride_time_left_3d > 0 else np.nan\n",
    "    gait_speed_right_3d = stride_length_right_3d / stride_time_right_3d if stride_time_right_3d > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (3D)\n",
    "    angles_3d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        def get_coords_3d(joint):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            return row[['X_3D', 'Y_3D', 'Z_3D']].values[0] if not row.empty else np.array([np.nan, np.nan, np.nan])\n",
    "\n",
    "        left_hip_3d = get_coords_3d('left_hip')\n",
    "        left_knee_3d = get_coords_3d('left_knee')\n",
    "        left_ankle_3d = get_coords_3d('left_ankle')\n",
    "        right_hip_3d = get_coords_3d('right_hip')\n",
    "        right_knee_3d = get_coords_3d('right_knee')\n",
    "        right_ankle_3d = get_coords_3d('right_ankle')\n",
    "        spine_3d = get_coords_3d('spine1')\n",
    "\n",
    "        def angle_between_3d(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        angles_3d['left_knee'].append(angle_between_3d(left_hip_3d - left_knee_3d, left_ankle_3d - left_knee_3d))\n",
    "        angles_3d['right_knee'].append(angle_between_3d(right_hip_3d - right_knee_3d, right_ankle_3d - right_knee_3d))\n",
    "        angles_3d['left_hip'].append(angle_between_3d(spine_3d - left_hip_3d, left_knee_3d - left_hip_3d))\n",
    "        angles_3d['right_hip'].append(angle_between_3d(spine_3d - right_hip_3d, right_knee_3d - right_hip_3d))\n",
    "\n",
    "    avg_angles_3d = {k: np.nanmean(v) for k, v in angles_3d.items()}\n",
    "\n",
    "    return {\n",
    "        'Person': person_id,\n",
    "        'Stride Time Left (s)': stride_time_left_3d,\n",
    "        'Stride Time Right (s)': stride_time_right_3d,\n",
    "        'Stride Length Left (m)': stride_length_left_3d,\n",
    "        'Stride Length Right (m)': stride_length_right_3d,\n",
    "        'Cadence (steps/min)': cadence_3d,\n",
    "        'Gait Speed Left (m/s)': gait_speed_left_3d,\n",
    "        'Gait Speed Right (m/s)': gait_speed_right_3d,\n",
    "        'Avg Left Knee Angle (deg)': avg_angles_3d['left_knee'],\n",
    "        'Avg Right Knee Angle (deg)': avg_angles_3d['right_knee'],\n",
    "        'Avg Left Hip Angle (deg)': avg_angles_3d['left_hip'],\n",
    "        'Avg Right Hip Angle (deg)': avg_angles_3d['right_hip']\n",
    "    }\n",
    "def main():\n",
    "    # Paths\n",
    "    zip_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\metrabs_mob3l_y4t.zip\"\n",
    "    video_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\video.mp4\"\n",
    "    output_excel = \"2dand3dposedatawithlabelschanged.xlsx\"\n",
    "\n",
    "    # Extract and load the model\n",
    "    model_path = extract_model(zip_path)\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    #model.summary()\n",
    "    print(dir(model))\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Load skeleton information\n",
    "    skeleton = 'smpl_24'\n",
    "    joint_names = model.per_skeleton_joint_names[skeleton].numpy().astype(str)\n",
    "    joint_edges = model.per_skeleton_joint_edges[skeleton].numpy()\n",
    "    \n",
    "\n",
    "    # Process video\n",
    "    process_video(video_path, model, joint_edges, output_excel=output_excel)\n",
    "\n",
    "    # Load the generated Excel file\n",
    "    df = pd.read_excel(output_excel)\n",
    "    fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Determine the number of unique persons detected\n",
    "    unique_persons = df['Person'].unique()\n",
    "    print(f\"Detected {len(unique_persons)} persons in the video.\")\n",
    "\n",
    "    # Calculate gait metrics for each detected person\n",
    "    metrics_2d_all = []\n",
    "    metrics_3d_all = []\n",
    "    for person_id in unique_persons:\n",
    "        print(f\"\\nProcessing Person {person_id}...\")\n",
    "        \n",
    "        # 2D Metrics\n",
    "        metrics_2d = calculate_gait_metrics_2d(df, person_id, fps, joint_edges, joint_names)\n",
    "        if metrics_2d:\n",
    "            metrics_2d_all.append(metrics_2d)\n",
    "            print(f\"2D Metrics for Person {person_id}:\")\n",
    "            for key, value in metrics_2d.items():\n",
    "                if key != 'Person':\n",
    "                    print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "        # 3D Metrics\n",
    "        metrics_3d = calculate_gait_metrics_3d(df, person_id, fps, joint_edges, joint_names)\n",
    "        if metrics_3d:\n",
    "            metrics_3d_all.append(metrics_3d)\n",
    "            print(f\"3D Metrics for Person {person_id}:\")\n",
    "            for key, value in metrics_3d.items():\n",
    "                if key != 'Person':\n",
    "                    print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "    # Save to Excel with separate sheets for 2D and 3D\n",
    "    metrics_df_2d = pd.DataFrame(metrics_2d_all)\n",
    "    metrics_df_3d = pd.DataFrame(metrics_3d_all)\n",
    "    with pd.ExcelWriter(\"gait_metrics_per_person.xlsx\") as writer:\n",
    "        metrics_df_2d.to_excel(writer, sheet_name='2D Metrics', index=False)\n",
    "        metrics_df_3d.to_excel(writer, sheet_name='3D Metrics', index=False)\n",
    "    print(\"\\nGait metrics for all detected persons saved to 'gait_metrics_per_person.xlsx'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Paths\n",
    "    zip_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\metrabs_mob3l_y4t.zip\"\n",
    "    video_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\video.mp4\"\n",
    "    output_excel = \"2dand3dposedatawithlabelschanged.xlsx\"\n",
    "\n",
    "    # Extract and load the model\n",
    "    model_path = extract_model(zip_path)\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Load skeleton information\n",
    "    skeleton = 'smpl_24'\n",
    "    joint_names = model.per_skeleton_joint_names[skeleton].numpy().astype(str)\n",
    "    joint_edges = model.per_skeleton_joint_edges[skeleton].numpy()\n",
    "\n",
    "    # Process video (this generates the initial Excel file with 2D in pixels, 3D in mm)\n",
    "    process_video(video_path, model, joint_edges, output_excel=output_excel)\n",
    "\n",
    "    # Load the generated Excel file\n",
    "    df = pd.read_excel(output_excel)\n",
    "\n",
    "    # Step 1: Compute the intrinsic matrix for the resized 640x480 image\n",
    "    width, height = 640, 480  # Resized image dimensions\n",
    "    fov_degrees = 55  # Default FOV from MeTRabs\n",
    "    f_x = (width / 2) / np.tan(np.radians(fov_degrees / 2))\n",
    "    f_y = f_x * (height / width)\n",
    "    c_x = width / 2\n",
    "    c_y = height / 2\n",
    "    intrinsic_matrix = np.array([\n",
    "        [f_x, 0, c_x],\n",
    "        [0, f_y, c_y],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    print(f\"Computed intrinsic matrix for 640x480 image:\\n{intrinsic_matrix}\")\n",
    "\n",
    "    # Adjust intrinsic matrix for original frame size\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    original_width = int(cap.get(3))\n",
    "    original_height = int(cap.get(4))\n",
    "    cap.release()\n",
    "    scale_x = original_width / 640\n",
    "    scale_y = original_height / 480\n",
    "    intrinsic_matrix[0, 0] *= scale_x  # Adjust f_x\n",
    "    intrinsic_matrix[1, 1] *= scale_y  # Adjust f_y\n",
    "    intrinsic_matrix[0, 2] *= scale_x  # Adjust c_x\n",
    "    intrinsic_matrix[1, 2] *= scale_y  # Adjust c_y\n",
    "    print(f\"Adjusted intrinsic matrix for original {original_width}x{original_height} resolution:\\n{intrinsic_matrix}\")\n",
    "\n",
    "    # Step 2: Compute pixel-to-mm scaling factors using depth\n",
    "    unique_persons = df['Person'].unique()\n",
    "    scale_factors_x = []\n",
    "    scale_factors_y = []\n",
    "\n",
    "    for person_id in unique_persons:\n",
    "        df_person = df[df['Person'] == person_id]\n",
    "        for frame in df_person['Frame'].unique():\n",
    "            frame_data = df_person[df_person['Frame'] == frame]\n",
    "            for joint in frame_data['Joint'].unique():\n",
    "                joint_data = frame_data[frame_data['Joint'] == joint]\n",
    "                if not joint_data.empty:\n",
    "                    u = joint_data['X_2D'].values[0]\n",
    "                    v = joint_data['Y_2D'].values[0]\n",
    "                    X = joint_data['X_3D'].values[0]\n",
    "                    Y = joint_data['Y_3D'].values[0]\n",
    "                    Z = joint_data['Z_3D'].values[0]\n",
    "\n",
    "                    if Z != 0:  # Avoid division by zero\n",
    "                        # Compute scaling factors using the pinhole model\n",
    "                        scale_x = X / (u - intrinsic_matrix[0, 2])\n",
    "                        scale_y = Y / (v - intrinsic_matrix[1, 2])\n",
    "\n",
    "                        # Alternative: Use Z directly\n",
    "                        # scale_x = Z / intrinsic_matrix[0, 0]\n",
    "                        # scale_y = Z / intrinsic_matrix[1, 1]\n",
    "\n",
    "                        if np.isfinite(scale_x) and np.isfinite(scale_y):\n",
    "                            scale_factors_x.append(scale_x)\n",
    "                            scale_factors_y.append(scale_y)\n",
    "\n",
    "    # Compute average scaling factors\n",
    "    if scale_factors_x and scale_factors_y:\n",
    "        scale_x = np.mean(scale_factors_x)\n",
    "        scale_y = np.mean(scale_factors_y)\n",
    "        print(f\"Computed pixel-to-mm scaling factors: scale_x = {scale_x:.4f} mm/pixel, scale_y = {scale_y:.4f} mm/pixel\")\n",
    "    else:\n",
    "        # Fallback: Use a reasonable default based on typical depth\n",
    "        scale_x = scale_y = 1.0  # Placeholder; adjust based on typical Z values if needed\n",
    "        print(\"Could not compute scaling factors. Using fallback: 1.0 mm/pixel\")\n",
    "\n",
    "    # Step 3: Convert 2D coordinates to millimeters\n",
    "    df['X_2D'] = (df['X_2D'] - intrinsic_matrix[0, 2]) * scale_x\n",
    "    df['Y_2D'] = (df['Y_2D'] - intrinsic_matrix[1, 2]) * scale_y\n",
    "\n",
    "    # Step 4: Save the updated Excel file with 2D and 3D coordinates in millimeters\n",
    "    updated_excel = \"2dand3dposedatawithlabelschanged_converted.xlsx\"\n",
    "    df.to_excel(updated_excel, index=False)\n",
    "    print(f\"Updated pose data with 2D coordinates in millimeters saved as {updated_excel}\")\n",
    "\n",
    "    # Step 5: Calculate gait metrics\n",
    "    fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"Detected {len(unique_persons)} persons in the video.\")\n",
    "\n",
    "    metrics_2d_all = []\n",
    "    metrics_3d_all = []\n",
    "    for person_id in unique_persons:\n",
    "        print(f\"\\nProcessing Person {person_id}...\")\n",
    "        \n",
    "        # 2D Metrics (now in millimeters)\n",
    "        metrics_2d = calculate_gait_metrics_2d(df, person_id, fps, joint_edges, joint_names)\n",
    "        if metrics_2d:\n",
    "            metrics_2d_all.append(metrics_2d)\n",
    "            print(f\"2D Metrics for Person {person_id}:\")\n",
    "            for key, value in metrics_2d.items():\n",
    "                if key != 'Person':\n",
    "                    print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "        # 3D Metrics (already in millimeters)\n",
    "        metrics_3d = calculate_gait_metrics_3d(df, person_id, fps, joint_edges, joint_names)\n",
    "        if metrics_3d:\n",
    "            metrics_3d_all.append(metrics_3d)\n",
    "            print(f\"3D Metrics for Person {person_id}:\")\n",
    "            for key, value in metrics_3d.items():\n",
    "                if key != 'Person':\n",
    "                    print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "    # Save to Excel with separate sheets for 2D and 3D\n",
    "    metrics_df_2d = pd.DataFrame(metrics_2d_all)\n",
    "    metrics_df_3d = pd.DataFrame(metrics_3d_all)\n",
    "    with pd.ExcelWriter(\"gait_metrics_per_person.xlsx\") as writer:\n",
    "        metrics_df_2d.to_excel(writer, sheet_name='2D Metrics', index=False)\n",
    "        metrics_df_3d.to_excel(writer, sheet_name='3D Metrics', index=False)\n",
    "    print(\"\\nGait metrics for all detected persons saved to 'gait_metrics_per_person.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Processed video saved as output_video3d_withlabelschanged.mp4\n",
      "Pose data saved as 2dand3dposedatawithlabelschanged.xlsx\n",
      "Computed pixel-to-mm conversion factor: 3.0609 mm/pixel\n",
      "Average 3D hip-to-ankle distance: 537.42 mm\n",
      "Average 2D hip-to-ankle distance: 107.36 pixels\n",
      "Updated pose data with 2D coordinates in millimeters saved as 2dand3dposedatawithlabelschanged_converted.xlsx\n",
      "Detected 8 persons in the video.\n",
      "\n",
      "Processing Person 0...\n",
      "2D Metrics for Person 0:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (mm): 1467.24\n",
      "Stride Length Right (mm): 1075.66\n",
      "Cadence (steps/min): 95.90\n",
      "Gait Speed Left (mm/s): 1172.62\n",
      "Gait Speed Right (mm/s): 859.67\n",
      "Avg Left Knee Angle (deg): 172.90\n",
      "Avg Right Knee Angle (deg): 160.95\n",
      "Avg Left Hip Angle (deg): 170.35\n",
      "Avg Right Hip Angle (deg): 160.23\n",
      "3D Metrics for Person 0:\n",
      "Stride Time Left (s): 0.97\n",
      "Stride Time Right (s): 1.08\n",
      "Stride Length Left (mm): 1597.56\n",
      "Stride Length Right (mm): 1089.24\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (mm/s): 1641.56\n",
      "Gait Speed Right (mm/s): 1004.44\n",
      "Avg Left Knee Angle (deg): 162.53\n",
      "Avg Right Knee Angle (deg): 161.61\n",
      "Avg Left Hip Angle (deg): 168.36\n",
      "Avg Right Hip Angle (deg): 163.25\n",
      "\n",
      "Processing Person 1...\n",
      "2D Metrics for Person 1:\n",
      "Stride Time Left (s): 1.36\n",
      "Stride Time Right (s): 1.56\n",
      "Stride Length Left (mm): 1689.14\n",
      "Stride Length Right (mm): 2072.43\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (mm/s): 1246.12\n",
      "Gait Speed Right (mm/s): 1325.03\n",
      "Avg Left Knee Angle (deg): 170.97\n",
      "Avg Right Knee Angle (deg): 164.42\n",
      "Avg Left Hip Angle (deg): 172.95\n",
      "Avg Right Hip Angle (deg): 161.18\n",
      "3D Metrics for Person 1:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.67\n",
      "Stride Length Left (mm): 814.72\n",
      "Stride Length Right (mm): 1193.24\n",
      "Cadence (steps/min): 71.93\n",
      "Gait Speed Left (mm/s): 651.12\n",
      "Gait Speed Right (mm/s): 715.23\n",
      "Avg Left Knee Angle (deg): 161.81\n",
      "Avg Right Knee Angle (deg): 166.18\n",
      "Avg Left Hip Angle (deg): 169.23\n",
      "Avg Right Hip Angle (deg): 164.69\n",
      "\n",
      "Processing Person 2...\n",
      "2D Metrics for Person 2:\n",
      "Stride Time Left (s): 1.33\n",
      "Stride Time Right (s): 1.67\n",
      "Stride Length Left (mm): 1451.06\n",
      "Stride Length Right (mm): 615.10\n",
      "Cadence (steps/min): 87.91\n",
      "Gait Speed Left (mm/s): 1087.21\n",
      "Gait Speed Right (mm/s): 368.69\n",
      "Avg Left Knee Angle (deg): 169.66\n",
      "Avg Right Knee Angle (deg): 157.98\n",
      "Avg Left Hip Angle (deg): 171.89\n",
      "Avg Right Hip Angle (deg): 161.66\n",
      "3D Metrics for Person 2:\n",
      "Stride Time Left (s): 1.39\n",
      "Stride Time Right (s): 1.39\n",
      "Stride Length Left (mm): 820.20\n",
      "Stride Length Right (mm): 851.42\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (mm/s): 589.95\n",
      "Gait Speed Right (mm/s): 612.41\n",
      "Avg Left Knee Angle (deg): 158.88\n",
      "Avg Right Knee Angle (deg): 160.15\n",
      "Avg Left Hip Angle (deg): 166.65\n",
      "Avg Right Hip Angle (deg): 163.72\n",
      "\n",
      "Processing Person 3...\n",
      "2D Metrics for Person 3:\n",
      "Stride Time Left (s): 0.97\n",
      "Stride Time Right (s): 0.97\n",
      "Stride Length Left (mm): 920.85\n",
      "Stride Length Right (mm): 936.73\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (mm/s): 946.21\n",
      "Gait Speed Right (mm/s): 962.54\n",
      "Avg Left Knee Angle (deg): 170.59\n",
      "Avg Right Knee Angle (deg): 163.82\n",
      "Avg Left Hip Angle (deg): 170.15\n",
      "Avg Right Hip Angle (deg): 162.17\n",
      "3D Metrics for Person 3:\n",
      "Stride Time Left (s): 1.56\n",
      "Stride Time Right (s): 1.56\n",
      "Stride Length Left (mm): 1762.73\n",
      "Stride Length Right (mm): 1839.48\n",
      "Cadence (steps/min): 79.92\n",
      "Gait Speed Left (mm/s): 1127.02\n",
      "Gait Speed Right (mm/s): 1176.09\n",
      "Avg Left Knee Angle (deg): 158.63\n",
      "Avg Right Knee Angle (deg): 161.61\n",
      "Avg Left Hip Angle (deg): 167.01\n",
      "Avg Right Hip Angle (deg): 163.86\n",
      "\n",
      "Processing Person 4...\n",
      "2D Metrics for Person 4:\n",
      "Stride Time Left (s): 2.22\n",
      "Stride Time Right (s): 2.22\n",
      "Stride Length Left (mm): 2307.14\n",
      "Stride Length Right (mm): 2302.71\n",
      "Cadence (steps/min): 63.94\n",
      "Gait Speed Left (mm/s): 1037.18\n",
      "Gait Speed Right (mm/s): 1035.19\n",
      "Avg Left Knee Angle (deg): 174.34\n",
      "Avg Right Knee Angle (deg): 163.91\n",
      "Avg Left Hip Angle (deg): 172.17\n",
      "Avg Right Hip Angle (deg): 162.19\n",
      "3D Metrics for Person 4:\n",
      "Stride Time Left (s): 1.46\n",
      "Stride Time Right (s): 1.46\n",
      "Stride Length Left (mm): 1378.12\n",
      "Stride Length Right (mm): 1504.38\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (mm/s): 944.05\n",
      "Gait Speed Right (mm/s): 1030.55\n",
      "Avg Left Knee Angle (deg): 163.74\n",
      "Avg Right Knee Angle (deg): 166.65\n",
      "Avg Left Hip Angle (deg): 169.17\n",
      "Avg Right Hip Angle (deg): 164.87\n",
      "\n",
      "Processing Person 5...\n",
      "2D Metrics for Person 5:\n",
      "Stride Time Left (s): 2.71\n",
      "Stride Time Right (s): 2.71\n",
      "Stride Length Left (mm): 614.50\n",
      "Stride Length Right (mm): 645.08\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (mm/s): 226.67\n",
      "Gait Speed Right (mm/s): 237.95\n",
      "Avg Left Knee Angle (deg): 153.69\n",
      "Avg Right Knee Angle (deg): 143.12\n",
      "Avg Left Hip Angle (deg): 153.64\n",
      "Avg Right Hip Angle (deg): 158.97\n",
      "3D Metrics for Person 5:\n",
      "Stride Time Left (s): 2.50\n",
      "Stride Time Right (s): 2.50\n",
      "Stride Length Left (mm): 1366.24\n",
      "Stride Length Right (mm): 1457.62\n",
      "Cadence (steps/min): 47.95\n",
      "Gait Speed Left (mm/s): 545.95\n",
      "Gait Speed Right (mm/s): 582.47\n",
      "Avg Left Knee Angle (deg): 136.69\n",
      "Avg Right Knee Angle (deg): 139.95\n",
      "Avg Left Hip Angle (deg): 154.97\n",
      "Avg Right Hip Angle (deg): 153.48\n",
      "\n",
      "Processing Person 6...\n",
      "2D Metrics for Person 6:\n",
      "Stride Time Left (s): N/A\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (mm): N/A\n",
      "Stride Length Right (mm): 69.65\n",
      "Cadence (steps/min): 26.97\n",
      "Gait Speed Left (mm/s): N/A\n",
      "Gait Speed Right (mm/s): 55.67\n",
      "Avg Left Knee Angle (deg): 149.71\n",
      "Avg Right Knee Angle (deg): 143.45\n",
      "Avg Left Hip Angle (deg): 146.64\n",
      "Avg Right Hip Angle (deg): 157.85\n",
      "3D Metrics for Person 6:\n",
      "Stride Time Left (s): 1.25\n",
      "Stride Time Right (s): 1.25\n",
      "Stride Length Left (mm): 1148.30\n",
      "Stride Length Right (mm): 1144.91\n",
      "Cadence (steps/min): 35.96\n",
      "Gait Speed Left (mm/s): 917.72\n",
      "Gait Speed Right (mm/s): 915.01\n",
      "Avg Left Knee Angle (deg): 132.05\n",
      "Avg Right Knee Angle (deg): 137.76\n",
      "Avg Left Hip Angle (deg): 150.92\n",
      "Avg Right Hip Angle (deg): 151.50\n",
      "\n",
      "Processing Person 7...\n",
      "2D Metrics for Person 7:\n",
      "Stride Time Left (s): N/A\n",
      "Stride Time Right (s): N/A\n",
      "Stride Length Left (mm): N/A\n",
      "Stride Length Right (mm): N/A\n",
      "Cadence (steps/min): N/A\n",
      "Gait Speed Left (mm/s): N/A\n",
      "Gait Speed Right (mm/s): N/A\n",
      "Avg Left Knee Angle (deg): 113.46\n",
      "Avg Right Knee Angle (deg): 113.22\n",
      "Avg Left Hip Angle (deg): 111.21\n",
      "Avg Right Hip Angle (deg): 154.55\n",
      "3D Metrics for Person 7:\n",
      "Stride Time Left (s): N/A\n",
      "Stride Time Right (s): N/A\n",
      "Stride Length Left (mm): N/A\n",
      "Stride Length Right (mm): N/A\n",
      "Cadence (steps/min): N/A\n",
      "Gait Speed Left (mm/s): N/A\n",
      "Gait Speed Right (mm/s): N/A\n",
      "Avg Left Knee Angle (deg): 85.26\n",
      "Avg Right Knee Angle (deg): 95.45\n",
      "Avg Left Hip Angle (deg): 122.27\n",
      "Avg Right Hip Angle (deg): 130.27\n",
      "\n",
      "Gait metrics for all detected persons saved to 'gait_metrics_per_person.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_io as tfio\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def extract_model(zip_path, extract_to=\"models\"):\n",
    "    \"\"\"Extracts a zip file and returns the extracted directory path.\"\"\"\n",
    "    extract_dir = os.path.join(os.path.dirname(zip_path), extract_to)\n",
    "\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    model_dir = os.path.join(extract_dir, os.path.splitext(os.path.basename(zip_path))[0])\n",
    "    return model_dir\n",
    "\n",
    "def draw_skeleton(frame, keypoints, skeleton_edges):\n",
    "    \"\"\"Draws skeleton on the frame using detected keypoints.\"\"\"\n",
    "    for (i, j) in skeleton_edges:\n",
    "        pt1, pt2 = keypoints[i], keypoints[j]\n",
    "\n",
    "        # Check if confidence is available (shape [N, 24, 3] expected)\n",
    "        if keypoints.shape[-1] == 3:  \n",
    "            if (pt1[2] > 0.5) and (pt2[2] > 0.5):  # Confidence threshold\n",
    "                cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)  # Blue lines\n",
    "        else:  \n",
    "            # Draw without confidence check\n",
    "            cv2.line(frame, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])), (255, 0, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# def process_video(video_path, model, skeleton_edges, output_video=\"output_video3d-36.mp4\", frame_interval=10, output_excel=\"2dand3dposedata.xlsx\"):\n",
    "#     \"\"\"Process video frames with pose estimation, overlay results, and save coordinates to an Excel file.\"\"\"\n",
    "    \n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     frame_width = int(cap.get(3))\n",
    "#     frame_height = int(cap.get(4))\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "#     frame_count = 0\n",
    "#     data_list = []  # Store pose data\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         if frame_count % frame_interval == 0:\n",
    "#             frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             original_height, original_width = frame.shape[:2]\n",
    "#             frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "#             image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "#             # Run pose estimation\n",
    "#             pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "\n",
    "#             if 'poses2d' in pred and 'poses3d' in pred:\n",
    "#                 keypoints_2d = pred['poses2d'].numpy()\n",
    "#                 keypoints_3d = pred['poses3d'].numpy()\n",
    "\n",
    "#                 if keypoints_2d.shape[0] == 0:\n",
    "#                     print(f\"No pose detected in frame {frame_count}\")\n",
    "#                 else:\n",
    "#                     # Convert normalized keypoints to pixel coordinates\n",
    "#                     for i in range(keypoints_2d.shape[0]):  # Iterate over detected poses\n",
    "#                         if keypoints_2d[i].shape[0] > 0 and keypoints_3d[i].shape[0] > 0:  # Check for valid keypoints\n",
    "#                             kpt_2d = keypoints_2d[i]  # Get keypoints for person i\n",
    "#                             kpt_3d = keypoints_3d[i]\n",
    "\n",
    "#                             # Scale keypoints to original frame size\n",
    "#                             kpt_2d[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "#                             kpt_2d[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "#                             frame = draw_skeleton(frame, kpt_2d, skeleton_edges)\n",
    "\n",
    "#                             # Store frame-wise keypoints\n",
    "#                             for j in range(min(kpt_2d.shape[0], kpt_3d.shape[0])):  # Ensure we only access valid joints\n",
    "#                                 data_list.append([\n",
    "#                                     frame_count, \n",
    "#                                     i, \n",
    "#                                     j, \n",
    "#                                     kpt_2d[j][0], \n",
    "#                                     kpt_2d[j][1], \n",
    "#                                     kpt_3d[j][0], \n",
    "#                                     kpt_3d[j][1], \n",
    "#                                     kpt_3d[j][2],  # Include Z coordinate for 3D keypoints\n",
    "#                                 ])\n",
    "#                         else:\n",
    "#                             print(f\"Invalid keypoints for frame {frame_count}, person {i}\")\n",
    "\n",
    "#         out.write(frame)  # Write frame to output video\n",
    "#         frame_count += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "\n",
    "#     # Convert collected data to a Pandas DataFrame\n",
    "#     df = pd.DataFrame(data_list, columns=['Frame', 'Person', 'Joint', 'X_2D', 'Y_2D', 'X_3D', 'Y_3D', 'Z_3D'])\n",
    "\n",
    "#     # Save to Excel file\n",
    "#     df.to_excel(output_excel, index=False)\n",
    "#     print(f\"Processed video saved as {output_video}\")\n",
    "#     print(f\"Pose data saved as {output_excel}\")\n",
    "def process_video(video_path, model, skeleton_edges, output_video=\"output_video3d_withlabelschanged.mp4\", frame_interval=10, output_excel=\"2dand3dposedatawithlabelschanged.xlsx\"):\n",
    "    \"\"\"Process video frames with pose estimation, overlay skeletons and person labels, and save coordinates to an Excel file.\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    data_list = []  # Store pose data\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            original_height, original_width = frame.shape[:2]\n",
    "            frame_rgb_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "            image_tensor = tf.convert_to_tensor(frame_rgb_resized, dtype=tf.uint8)\n",
    "\n",
    "            # Run pose estimation\n",
    "            pred = model.detect_poses(image_tensor, skeleton='smpl_24')\n",
    "\n",
    "            if 'poses2d' in pred and 'poses3d' in pred:\n",
    "                keypoints_2d = pred['poses2d'].numpy()\n",
    "                keypoints_3d = pred['poses3d'].numpy()\n",
    "\n",
    "                if keypoints_2d.shape[0] == 0:\n",
    "                    print(f\"No pose detected in frame {frame_count}\")\n",
    "                else:\n",
    "                    # Iterate over detected poses (persons)\n",
    "                    for i in range(keypoints_2d.shape[0]):\n",
    "                        if keypoints_2d[i].shape[0] > 0 and keypoints_3d[i].shape[0] > 0:  # Check for valid keypoints\n",
    "                            kpt_2d = keypoints_2d[i]  # Get keypoints for person i\n",
    "                            kpt_3d = keypoints_3d[i]\n",
    "\n",
    "                            # Scale keypoints to original frame size\n",
    "                            kpt_2d[:, 0] *= original_width / 640  # Scale x-coordinates\n",
    "                            kpt_2d[:, 1] *= original_height / 480  # Scale y-coordinates\n",
    "\n",
    "                            # Draw skeleton\n",
    "                            frame = draw_skeleton(frame, kpt_2d, skeleton_edges)\n",
    "\n",
    "                            # Add person label (e.g., \"Person 1\", \"Person 2\", etc.)\n",
    "                            person_label = f\"Person {i + 1}\"  # Person ID starts from 1\n",
    "                            label_position = (int(kpt_2d[0][0]), int(kpt_2d[0][1] - 20))  # Position above the head (e.g., pelvis or first keypoint)\n",
    "                            cv2.putText(frame, person_label, label_position, \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                            # Store frame-wise keypoints\n",
    "                            for j in range(min(kpt_2d.shape[0], kpt_3d.shape[0])):  # Ensure we only access valid joints\n",
    "                                data_list.append([\n",
    "                                    frame_count, \n",
    "                                    i, \n",
    "                                    j, \n",
    "                                    kpt_2d[j][0], \n",
    "                                    kpt_2d[j][1], \n",
    "                                    kpt_3d[j][0], \n",
    "                                    kpt_3d[j][1], \n",
    "                                    kpt_3d[j][2],  # Include Z coordinate for 3D keypoints\n",
    "                                ])\n",
    "                        else:\n",
    "                            print(f\"Invalid keypoints for frame {frame_count}, person {i}\")\n",
    "\n",
    "        out.write(frame)  # Write frame to output video\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Convert collected data to a Pandas DataFrame\n",
    "    df = pd.DataFrame(data_list, columns=['Frame', 'Person', 'Joint', 'X_2D', 'Y_2D', 'X_3D', 'Y_3D', 'Z_3D'])\n",
    "\n",
    "    # Save to Excel file\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Processed video saved as {output_video}\")\n",
    "    print(f\"Pose data saved as {output_excel}\")\n",
    "\n",
    "def calculate_gait_metrics_2d(df, person_id, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate 2D gait metrics for a specific person.\"\"\"\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    df_person = df[df['Person'] == person_id]\n",
    "    if df_person.empty:\n",
    "        return None  # No data for this person\n",
    "\n",
    "    left_ankle_2d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "    right_ankle_2d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_2D', 'Y_2D']].values\n",
    "\n",
    "    # Detect heel strikes in 2D (lowest Y_2D position)\n",
    "    left_strikes_2d = []\n",
    "    right_strikes_2d = []\n",
    "    for i in range(1, len(left_ankle_2d) - 1):\n",
    "        if left_ankle_2d[i][2] < left_ankle_2d[i-1][2] and left_ankle_2d[i][2] < left_ankle_2d[i+1][2]:\n",
    "            left_strikes_2d.append(left_ankle_2d[i])\n",
    "        if right_ankle_2d[i][2] < right_ankle_2d[i-1][2] and right_ankle_2d[i][2] < right_ankle_2d[i+1][2]:\n",
    "            right_strikes_2d.append(right_ankle_2d[i])\n",
    "\n",
    "    left_strikes_2d = np.array(left_strikes_2d)\n",
    "    right_strikes_2d = np.array(right_strikes_2d)\n",
    "\n",
    "    # 1. Stride Time (2D)\n",
    "    stride_time_left_2d = np.mean(np.diff(left_strikes_2d[:, 0]) / fps) if len(left_strikes_2d) > 1 else np.nan\n",
    "    stride_time_right_2d = np.mean(np.diff(right_strikes_2d[:, 0]) / fps) if len(right_strikes_2d) > 1 else np.nan\n",
    "\n",
    "    # 2. Stride Length (2D, in pixels)\n",
    "    stride_length_left_2d = np.mean([distance.euclidean(left_strikes_2d[i][1:3], left_strikes_2d[i+1][1:3]) \n",
    "                                    for i in range(len(left_strikes_2d)-1)]) if len(left_strikes_2d) > 1 else np.nan\n",
    "    stride_length_right_2d = np.mean([distance.euclidean(right_strikes_2d[i][1:3], right_strikes_2d[i+1][1:3]) \n",
    "                                     for i in range(len(right_strikes_2d)-1)]) if len(right_strikes_2d) > 1 else np.nan\n",
    "\n",
    "    # 3. Cadence (2D)\n",
    "    total_steps_2d = len(left_strikes_2d) + len(right_strikes_2d)\n",
    "    total_time_2d = (df_person['Frame'].max() - df_person['Frame'].min()) / fps / 60 if not df_person['Frame'].empty else 0\n",
    "    cadence_2d = total_steps_2d / total_time_2d if total_time_2d > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (2D, pixels per second)\n",
    "    gait_speed_left_2d = stride_length_left_2d / stride_time_left_2d if stride_time_left_2d > 0 else np.nan\n",
    "    gait_speed_right_2d = stride_length_right_2d / stride_time_right_2d if stride_time_right_2d > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (2D)\n",
    "    angles_2d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        def get_coords_2d(joint):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            return row[['X_2D', 'Y_2D']].values[0] if not row.empty else np.array([np.nan, np.nan])\n",
    "\n",
    "        left_hip_2d = get_coords_2d('left_hip')\n",
    "        left_knee_2d = get_coords_2d('left_knee')\n",
    "        left_ankle_2d = get_coords_2d('left_ankle')\n",
    "        right_hip_2d = get_coords_2d('right_hip')\n",
    "        right_knee_2d = get_coords_2d('right_knee')\n",
    "        right_ankle_2d = get_coords_2d('right_ankle')\n",
    "        spine_2d = get_coords_2d('spine1')\n",
    "\n",
    "        def angle_between_2d(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        angles_2d['left_knee'].append(angle_between_2d(left_hip_2d - left_knee_2d, left_ankle_2d - left_knee_2d))\n",
    "        angles_2d['right_knee'].append(angle_between_2d(right_hip_2d - right_knee_2d, right_ankle_2d - right_knee_2d))\n",
    "        angles_2d['left_hip'].append(angle_between_2d(spine_2d - left_hip_2d, left_knee_2d - left_hip_2d))\n",
    "        angles_2d['right_hip'].append(angle_between_2d(spine_2d - right_hip_2d, right_knee_2d - right_hip_2d))\n",
    "\n",
    "    avg_angles_2d = {k: np.nanmean(v) for k, v in angles_2d.items()}\n",
    "\n",
    "    return {\n",
    "        'Person': person_id,\n",
    "        'Stride Time Left (s)': stride_time_left_2d,\n",
    "        'Stride Time Right (s)': stride_time_right_2d,\n",
    "        'Stride Length Left (mm)': stride_length_left_2d,\n",
    "        'Stride Length Right (mm)': stride_length_right_2d,\n",
    "        'Cadence (steps/min)': cadence_2d,\n",
    "        'Gait Speed Left (mm/s)': gait_speed_left_2d,\n",
    "        'Gait Speed Right (mm/s)': gait_speed_right_2d,\n",
    "        'Avg Left Knee Angle (deg)': avg_angles_2d['left_knee'],\n",
    "        'Avg Right Knee Angle (deg)': avg_angles_2d['right_knee'],\n",
    "        'Avg Left Hip Angle (deg)': avg_angles_2d['left_hip'],\n",
    "        'Avg Right Hip Angle (deg)': avg_angles_2d['right_hip']\n",
    "    }\n",
    "def calculate_gait_metrics_3d(df, person_id, fps, skeleton_edges, joint_names):\n",
    "    \"\"\"Calculate 3D gait metrics for a specific person.\"\"\"\n",
    "    joint_map = {\n",
    "        'pelvis': 0, 'left_hip': 1, 'right_hip': 2, 'spine1': 3,\n",
    "        'left_knee': 4, 'right_knee': 5, 'spine2': 6,\n",
    "        'left_ankle': 7, 'right_ankle': 8\n",
    "    }\n",
    "\n",
    "    df_person = df[df['Person'] == person_id]\n",
    "    if df_person.empty:\n",
    "        return None  # No data for this person\n",
    "\n",
    "    left_ankle_3d = df_person[df_person['Joint'] == joint_map['left_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "    right_ankle_3d = df_person[df_person['Joint'] == joint_map['right_ankle']][['Frame', 'X_3D', 'Y_3D', 'Z_3D']].values\n",
    "\n",
    "    # Detect heel strikes in 3D (lowest Z_3D position)\n",
    "    left_strikes_3d = []\n",
    "    right_strikes_3d = []\n",
    "    for i in range(1, len(left_ankle_3d) - 1):\n",
    "        if left_ankle_3d[i][3] < left_ankle_3d[i-1][3] and left_ankle_3d[i][3] < left_ankle_3d[i+1][3]:\n",
    "            left_strikes_3d.append(left_ankle_3d[i])\n",
    "        if right_ankle_3d[i][3] < right_ankle_3d[i-1][3] and right_ankle_3d[i][3] < right_ankle_3d[i+1][3]:\n",
    "            right_strikes_3d.append(right_ankle_3d[i])\n",
    "\n",
    "    left_strikes_3d = np.array(left_strikes_3d)\n",
    "    right_strikes_3d = np.array(right_strikes_3d)\n",
    "\n",
    "    # 1. Stride Time (3D)\n",
    "    stride_time_left_3d = np.mean(np.diff(left_strikes_3d[:, 0]) / fps) if len(left_strikes_3d) > 1 else np.nan\n",
    "    stride_time_right_3d = np.mean(np.diff(right_strikes_3d[:, 0]) / fps) if len(right_strikes_3d) > 1 else np.nan\n",
    "\n",
    "    # 2. Stride Length (3D, assumed meters)\n",
    "    stride_length_left_3d = np.mean([distance.euclidean(left_strikes_3d[i][1:4], left_strikes_3d[i+1][1:4]) \n",
    "                                    for i in range(len(left_strikes_3d)-1)]) if len(left_strikes_3d) > 1 else np.nan\n",
    "    stride_length_right_3d = np.mean([distance.euclidean(right_strikes_3d[i][1:4], right_strikes_3d[i+1][1:4]) \n",
    "                                     for i in range(len(right_strikes_3d)-1)]) if len(right_strikes_3d) > 1 else np.nan\n",
    "\n",
    "    # 3. Cadence (3D)\n",
    "    total_steps_3d = len(left_strikes_3d) + len(right_strikes_3d)\n",
    "    total_time_3d = (df_person['Frame'].max() - df_person['Frame'].min()) / fps / 60 if not df_person['Frame'].empty else 0\n",
    "    cadence_3d = total_steps_3d / total_time_3d if total_time_3d > 0 else np.nan\n",
    "\n",
    "    # 4. Gait Speed (3D, assumed meters per second)\n",
    "    gait_speed_left_3d = stride_length_left_3d / stride_time_left_3d if stride_time_left_3d > 0 else np.nan\n",
    "    gait_speed_right_3d = stride_length_right_3d / stride_time_right_3d if stride_time_right_3d > 0 else np.nan\n",
    "\n",
    "    # 5. Knee and Hip Angles (3D)\n",
    "    angles_3d = {'left_knee': [], 'right_knee': [], 'left_hip': [], 'right_hip': []}\n",
    "    for frame in df_person['Frame'].unique():\n",
    "        frame_data = df_person[df_person['Frame'] == frame]\n",
    "        \n",
    "        def get_coords_3d(joint):\n",
    "            row = frame_data[frame_data['Joint'] == joint_map[joint]]\n",
    "            return row[['X_3D', 'Y_3D', 'Z_3D']].values[0] if not row.empty else np.array([np.nan, np.nan, np.nan])\n",
    "\n",
    "        left_hip_3d = get_coords_3d('left_hip')\n",
    "        left_knee_3d = get_coords_3d('left_knee')\n",
    "        left_ankle_3d = get_coords_3d('left_ankle')\n",
    "        right_hip_3d = get_coords_3d('right_hip')\n",
    "        right_knee_3d = get_coords_3d('right_knee')\n",
    "        right_ankle_3d = get_coords_3d('right_ankle')\n",
    "        spine_3d = get_coords_3d('spine1')\n",
    "\n",
    "        def angle_between_3d(v1, v2):\n",
    "            if np.any(np.isnan(v1)) or np.any(np.isnan(v2)):\n",
    "                return np.nan\n",
    "            cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            return np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "\n",
    "        angles_3d['left_knee'].append(angle_between_3d(left_hip_3d - left_knee_3d, left_ankle_3d - left_knee_3d))\n",
    "        angles_3d['right_knee'].append(angle_between_3d(right_hip_3d - right_knee_3d, right_ankle_3d - right_knee_3d))\n",
    "        angles_3d['left_hip'].append(angle_between_3d(spine_3d - left_hip_3d, left_knee_3d - left_hip_3d))\n",
    "        angles_3d['right_hip'].append(angle_between_3d(spine_3d - right_hip_3d, right_knee_3d - right_hip_3d))\n",
    "\n",
    "    avg_angles_3d = {k: np.nanmean(v) for k, v in angles_3d.items()}\n",
    "\n",
    "    return {\n",
    "        'Person': person_id,\n",
    "        'Stride Time Left (s)': stride_time_left_3d,\n",
    "        'Stride Time Right (s)': stride_time_right_3d,\n",
    "        'Stride Length Left (mm)': stride_length_left_3d,\n",
    "        'Stride Length Right (mm)': stride_length_right_3d,\n",
    "        'Cadence (steps/min)': cadence_3d,\n",
    "        'Gait Speed Left (mm/s)': gait_speed_left_3d,\n",
    "        'Gait Speed Right (mm/s)': gait_speed_right_3d,\n",
    "        'Avg Left Knee Angle (deg)': avg_angles_3d['left_knee'],\n",
    "        'Avg Right Knee Angle (deg)': avg_angles_3d['right_knee'],\n",
    "        'Avg Left Hip Angle (deg)': avg_angles_3d['left_hip'],\n",
    "        'Avg Right Hip Angle (deg)': avg_angles_3d['right_hip']\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    zip_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\metrabs_mob3l_y4t.zip\"\n",
    "    video_path = \"C:\\\\Users\\\\akhileshsing2024\\\\Downloads\\\\video.mp4\"\n",
    "    output_excel = \"2dand3dposedatawithlabelschanged.xlsx\"\n",
    "\n",
    "    # Extract and load the model\n",
    "    model_path = extract_model(zip_path)\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Load skeleton information\n",
    "    skeleton = 'smpl_24'\n",
    "    joint_names = model.per_skeleton_joint_names[skeleton].numpy().astype(str)\n",
    "    joint_edges = model.per_skeleton_joint_edges[skeleton].numpy()\n",
    "\n",
    "    # Process video (this generates the initial Excel file with 2D in pixels, 3D in mm)\n",
    "    process_video(video_path, model, joint_edges, output_excel=output_excel)\n",
    "\n",
    "    # Load the generated Excel file\n",
    "    df = pd.read_excel(output_excel)\n",
    "\n",
    "    # Step 1: Compute pixel-to-mm conversion factor using hip-to-ankle distance\n",
    "    unique_persons = df['Person'].unique()\n",
    "    pixel_to_mm_factors = []\n",
    "\n",
    "    for person_id in unique_persons:\n",
    "        df_person = df[df['Person'] == person_id]\n",
    "        \n",
    "        # Extract hip and ankle coordinates for all frames\n",
    "        left_hip_2d = df_person[df_person['Joint'] == 1][['Frame', 'X_2D', 'Y_2D']]\n",
    "        left_ankle_2d = df_person[df_person['Joint'] == 7][['Frame', 'X_2D', 'Y_2D']]\n",
    "        left_hip_3d = df_person[df_person['Joint'] == 1][['Frame', 'X_3D', 'Y_3D', 'Z_3D']]\n",
    "        left_ankle_3d = df_person[df_person['Joint'] == 7][['Frame', 'X_3D', 'Y_3D', 'Z_3D']]\n",
    "\n",
    "        # Merge on Frame to get corresponding hip and ankle coordinates\n",
    "        hip_ankle_2d = left_hip_2d.merge(left_ankle_2d, on='Frame', suffixes=('_hip', '_ankle'))\n",
    "        hip_ankle_3d = left_hip_3d.merge(left_ankle_3d, on='Frame', suffixes=('_hip', '_ankle'))\n",
    "\n",
    "        # Compute distances for each frame\n",
    "        distances_2d = []\n",
    "        distances_3d = []\n",
    "        for idx in range(len(hip_ankle_2d)):\n",
    "            # 2D distance (pixels)\n",
    "            hip_2d = hip_ankle_2d.iloc[idx][['X_2D_hip', 'Y_2D_hip']].values\n",
    "            ankle_2d = hip_ankle_2d.iloc[idx][['X_2D_ankle', 'Y_2D_ankle']].values\n",
    "            dist_2d = distance.euclidean(hip_2d, ankle_2d)\n",
    "\n",
    "            # 3D distance (mm)\n",
    "            hip_3d = hip_ankle_3d.iloc[idx][['X_3D_hip', 'Y_3D_hip', 'Z_3D_hip']].values\n",
    "            ankle_3d = hip_ankle_3d.iloc[idx][['X_3D_ankle', 'Y_3D_ankle', 'Z_3D_ankle']].values\n",
    "            dist_3d = distance.euclidean(hip_3d, ankle_3d)\n",
    "\n",
    "            if dist_2d > 0:  # Avoid division by zero\n",
    "                pixel_to_mm = dist_3d / dist_2d\n",
    "                pixel_to_mm_factors.append(pixel_to_mm)\n",
    "                distances_2d.append(dist_2d)\n",
    "                distances_3d.append(dist_3d)\n",
    "\n",
    "    # Compute the average pixel-to-mm factor\n",
    "    if pixel_to_mm_factors:\n",
    "        pixel_to_mm = np.mean(pixel_to_mm_factors)\n",
    "        print(f\"Computed pixel-to-mm conversion factor: {pixel_to_mm:.4f} mm/pixel\")\n",
    "        print(f\"Average 3D hip-to-ankle distance: {np.mean(distances_3d):.2f} mm\")\n",
    "        print(f\"Average 2D hip-to-ankle distance: {np.mean(distances_2d):.2f} pixels\")\n",
    "    else:\n",
    "        # Fallback to anthropometric average if no valid distances are computed\n",
    "        pixel_to_mm = 900 / 500  # Assume 900 mm leg length, 500 pixels in 2D (rough estimate)\n",
    "        print(f\"No valid distances computed. Using fallback pixel-to-mm factor: {pixel_to_mm:.4f} mm/pixel\")\n",
    "\n",
    "    # Step 2: Convert 2D coordinates to millimeters\n",
    "    df['X_2D'] = df['X_2D'] * pixel_to_mm\n",
    "    df['Y_2D'] = df['Y_2D'] * pixel_to_mm\n",
    "\n",
    "    # Step 3: Save the updated Excel file with 2D and 3D coordinates in millimeters\n",
    "    updated_excel = \"2dand3dposedatawithlabelschanged_converted.xlsx\"\n",
    "    df.to_excel(updated_excel, index=False)\n",
    "    print(f\"Updated pose data with 2D coordinates in millimeters saved as {updated_excel}\")\n",
    "\n",
    "    # Step 4: Calculate gait metrics\n",
    "    fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"Detected {len(unique_persons)} persons in the video.\")\n",
    "\n",
    "    metrics_2d_all = []\n",
    "    metrics_3d_all = []\n",
    "    for person_id in unique_persons:\n",
    "        print(f\"\\nProcessing Person {person_id}...\")\n",
    "        \n",
    "        # 2D Metrics (now in millimeters)\n",
    "        metrics_2d = calculate_gait_metrics_2d(df, person_id, fps, joint_edges, joint_names)\n",
    "        if metrics_2d:\n",
    "            metrics_2d_all.append(metrics_2d)\n",
    "            print(f\"2D Metrics for Person {person_id}:\")\n",
    "            for key, value in metrics_2d.items():\n",
    "                if key != 'Person':\n",
    "                    print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "        # 3D Metrics (already in millimeters)\n",
    "        metrics_3d = calculate_gait_metrics_3d(df, person_id, fps, joint_edges, joint_names)\n",
    "        if metrics_3d:\n",
    "            metrics_3d_all.append(metrics_3d)\n",
    "            print(f\"3D Metrics for Person {person_id}:\")\n",
    "            for key, value in metrics_3d.items():\n",
    "                if key != 'Person':\n",
    "                    print(f\"{key}: {value:.2f}\" if not np.isnan(value) else f\"{key}: N/A\")\n",
    "\n",
    "    # Save to Excel with separate sheets for 2D and 3D\n",
    "    metrics_df_2d = pd.DataFrame(metrics_2d_all)\n",
    "    metrics_df_3d = pd.DataFrame(metrics_3d_all)\n",
    "    with pd.ExcelWriter(\"gait_metrics_per_person.xlsx\") as writer:\n",
    "        metrics_df_2d.to_excel(writer, sheet_name='2D Metrics', index=False)\n",
    "        metrics_df_3d.to_excel(writer, sheet_name='3D Metrics', index=False)\n",
    "    print(\"\\nGait metrics for all detected persons saved to 'gait_metrics_per_person.xlsx'\")\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
